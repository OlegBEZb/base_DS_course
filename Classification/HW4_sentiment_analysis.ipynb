{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhA6jSmagH5e"
   },
   "source": [
    "# Installing the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "y2AehcFQr6ET",
    "outputId": "f0324222-8bbc-4b1c-f65d-ef28160ef2e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/TeamHG-Memex/eli5@0.8.2\n",
      "  Cloning https://github.com/TeamHG-Memex/eli5 (to revision 0.8.2) to c:\\users\\oleg\\appdata\\local\\temp\\pip-req-build-wdsfo5xq\n",
      "Requirement already satisfied: attrs>16.0.0 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (19.1.0)\n",
      "Requirement already satisfied: jinja2 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (1.16.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\oleg\\appdata\\roaming\\python\\python36\\site-packages (from eli5==0.8.2) (1.5.0)\n",
      "Requirement already satisfied: six in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (0.21.2)\n",
      "Collecting typing (from eli5==0.8.2)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d9/6eebe19d46bd05360c9a9aae822e67a80f9242aabbfc58b641b957546607/typing-3.7.4.3.tar.gz (78kB)\n",
      "Requirement already satisfied: graphviz in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (0.8.4)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from eli5==0.8.2) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from jinja2->eli5==0.8.2) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\programs\\ide_and_for_programming\\anaconda\\lib\\site-packages (from scikit-learn>=0.18->eli5==0.8.2) (0.13.2)\n",
      "Building wheels for collected packages: eli5, typing\n",
      "  Building wheel for eli5 (setup.py): started\n",
      "  Building wheel for eli5 (setup.py): finished with status 'done'\n",
      "  Created wheel for eli5: filename=eli5-0.8.2-py2.py3-none-any.whl size=94040 sha256=85cea1a523e42aa71518e1d1021d4aabc85c50be8cd9e95f6863e9d12ece740d\n",
      "  Stored in directory: C:\\Users\\Oleg\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-arblboar\\wheels\\d6\\9e\\ef\\cf023b7bfc3f7a988a27ddefb645f3f33e6019be21f1c6af54\n",
      "  Building wheel for typing (setup.py): started\n",
      "  Building wheel for typing (setup.py): finished with status 'done'\n",
      "  Created wheel for typing: filename=typing-3.7.4.3-cp36-none-any.whl size=26314 sha256=3b9bde739b9f790960b4c06cf4cbffaa5f352cda68036fee32c4c7823013eea8\n",
      "  Stored in directory: C:\\Users\\Oleg\\AppData\\Local\\pip\\Cache\\wheels\\2d\\04\\41\\8e1836e79581989c22eebac3f4e70aaac9af07b0908da173be\n",
      "Successfully built eli5 typing\n",
      "Installing collected packages: typing, eli5\n",
      "  Found existing installation: eli5 0.8\n",
      "    Uninstalling eli5-0.8:\n",
      "      Successfully uninstalled eli5-0.8\n",
      "Successfully installed eli5-0.8.2 typing-3.7.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/TeamHG-Memex/eli5 'C:\\Users\\Oleg\\AppData\\Local\\Temp\\pip-req-build-wdsfo5xq'\n",
      "  Running command git checkout -q 0b226d76bde4b71125a5ab1e701a8dd5522b2f86\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/TeamHG-Memex/eli5@0.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Ao5khs6Wrclt",
    "outputId": "6d16a31e-bccf-490d-fc76-d681500c8f65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Oleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Oleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Oleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['stopwords', 'punkt', 'wordnet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OH9donQlSOh9"
   },
   "source": [
    "# Loading needed libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMuQFLjZgH5g"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer, FunctionTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA as iPCA, TruncatedSVD\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "from textblob import TextBlob, Word\n",
    "from random import shuffle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from eli5.lime import TextExplainer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eeiQyXv_gH5n"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-9ciVPxZgsB"
   },
   "source": [
    "Download https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews  \n",
    "Files->Upload to session storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sx3Oy67GcBKG",
    "outputId": "e1680457-800c-4470-ab2b-005e41fff1bb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "cLGcD-KojbAp",
    "outputId": "c049bbeb-bb4f-47a4-b11b-d6b373b8c273"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  One of the other reviewers has mentioned that ...       1\n",
       "1  A wonderful little production. <br /><br />The...       1\n",
       "2  I thought this was a wonderful way to spend ti...       1\n",
       "3  Basically there's a family where a little boy ...       0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={'sentiment': 'target'}, inplace=True)\n",
    "data['target'].replace({'positive': 1, 'negative': 0}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CWeO8b6TcMGn",
    "outputId": "6647938f-c310-4dc8-b78b-35c10163f8b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgktDBHOgH6H"
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffdQD5DNcy4G"
   },
   "outputs": [],
   "source": [
    "def show_mean_feature_value_for_both(col, normalize_by_word_count=False):\n",
    "    print('Average {} in positive review: {}'.format(col, data[data['target'] == 1][col].mean()))\n",
    "    print('Average {} in negative review: {}'.format(col, data[data['target'] == 0][col].mean()))\n",
    "    if normalize_by_word_count:\n",
    "        print('Average ratio of {} in positive review: {}'.format(col, data[data['target'] == 1][col].mean() / data[data['target'] == 1]['word_count'].mean()))\n",
    "        print('Average ratio of {} in positive review: {}'.format(col, data[data['target'] == 0][col].mean() / data[data['target'] == 0]['word_count'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-7z-lLHgH6I"
   },
   "source": [
    "#### Number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDlUcLYygH6K"
   },
   "source": [
    "Check if number of words in review can predict the grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-qAnERKOdy7O",
    "outputId": "6ec51718-42c4-4b58-a540-1b2a78a4d9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word_count in positive review: 232.83776\n",
      "Average word_count in negative review: 229.45412\n"
     ]
    }
   ],
   "source": [
    "data['word_count'] = data['review'].apply(lambda x: len(str(x).split(\" \")))\n",
    "show_mean_feature_value_for_both('word_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgRsT7hlgH6P"
   },
   "source": [
    "For negative and positive comments number of words is almost identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WgmVUTwxgH6R"
   },
   "source": [
    "#### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "flTc1U1UgH6R",
    "outputId": "481785be-81e7-4762-a106-98500ef48968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average avg_word in positive review: 4.657891605718888\n",
      "Average avg_word in negative review: 4.62346073050112\n"
     ]
    }
   ],
   "source": [
    "def avg_word(review):\n",
    "    words = review.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['review'].apply(lambda x: avg_word(x))\n",
    "show_mean_feature_value_for_both('avg_word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBrCvcQWgH6W"
   },
   "source": [
    "There is no difference here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6zkxIvwgH6X"
   },
   "source": [
    "#### Number of stopwords\n",
    "\n",
    "Before changing and removing the stopwords let's try to find some patterns with default list of stopwords from NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "fPNi8q8JfAlK",
    "outputId": "cfcad330-9d1f-49f5-a9c5-cfe34c8d6c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average stopwords in positive review: 95.5394\n",
      "Average stopwords in negative review: 93.99816\n",
      "Average ratio of stopwords in positive review: 0.41032605707940156\n",
      "Average ratio of stopwords in positive review: 0.40965993550257457\n"
     ]
    }
   ],
   "source": [
    "data['stopwords'] = data['review'].apply(lambda x: len([x for x in x.split() if x in cachedStopWords]))\n",
    "show_mean_feature_value_for_both('stopwords', normalize_by_word_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uUVVZZsgH6d"
   },
   "source": [
    "And now there is nothing notable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJ7Hun2lgH6e"
   },
   "source": [
    "#### Number of swear words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jsd76RIYfVWu",
    "outputId": "fa7975f1-316d-49d0-d8ee-b1ab940dcc76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average swear_words in positive review: 0.01476\n",
      "Average swear_words in negative review: 0.01728\n",
      "Average ratio of swear_words in positive review: 6.339177975256248e-05\n",
      "Average ratio of swear_words in positive review: 7.53091729187517e-05\n"
     ]
    }
   ],
   "source": [
    "#collecting swear words (shifted to the right) and present them in two cases: low and with capital letter\n",
    "swear_words=[                                                                                                                                                                                       'Bastard', 'Beaver', 'Bellend', 'Bloodclaat', 'Clunge', 'Cock', 'Dick', 'Dickhead', 'Fanny', 'Flaps', 'Gash', 'Knob', 'Minge', 'Prick', 'Punani', 'Pussy', 'Snatch', 'Twat', 'Cunt', 'Fuck', 'Motherfucker', 'Arsehole', 'Balls', 'Bint', 'Bitch', 'Bollocks', 'Bullshit', 'Feck', 'Munter', 'pissed off', 'Shit', 'Son of a bitch', 'Tits']\n",
    "swear_words += [word.lower() for word in swear_words]\n",
    "\n",
    "data['swear_words'] = data['review'].apply(lambda x: len([x for x in x.split() if x in swear_words]))\n",
    "show_mean_feature_value_for_both('swear_words', normalize_by_word_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSTcxXUWgH6j"
   },
   "source": [
    "Both categories have similar frequencies (very small) of swear words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxVs0fnagH6k"
   },
   "source": [
    "#### Number of numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Buu4d-7DfzP5",
    "outputId": "2be9f16d-190b-4f44-fd06-13ae3a1615c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average numerics in positive review: 0.52252\n",
      "Average numerics in negative review: 0.61912\n",
      "Average ratio of numerics in positive review: 0.002244137720617137\n",
      "Average ratio of numerics in positive review: 0.0026982300426769412\n"
     ]
    }
   ],
   "source": [
    "data['numerics'] = data['review'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "show_mean_feature_value_for_both('numerics', normalize_by_word_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lS0cLH2HgH6p"
   },
   "source": [
    "Parts of numerics in reviews are small and that there is no visible differense betweed categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aWkJtYPgH6r"
   },
   "source": [
    "#### Number of Uppercase words (CAPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yKkVszpWgAdU",
    "outputId": "e6602934-a236-4206-8f65-5fb73030fec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average upper in positive review: 4.56928\n",
      "Average upper in negative review: 5.14632\n",
      "Average ratio of upper in positive review: 0.019624308359606275\n",
      "Average ratio of upper in positive review: 0.02242853604023323\n"
     ]
    }
   ],
   "source": [
    "data['upper'] = data['review'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "show_mean_feature_value_for_both('upper', normalize_by_word_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EY2C8xOgH6y"
   },
   "source": [
    "And now there is nothing suspicious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1A_wXTG2gH6z"
   },
   "source": [
    "#### Number of punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "xbt5G9logJGJ",
    "outputId": "625bce9f-b9f5-4314-e29f-3ce405aefc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average punctuation_marks in positive review: 36.09288\n",
      "Average punctuation_marks in negative review: 37.41992\n",
      "Average ratio of punctuation_marks in positive review: 0.15501300132761972\n",
      "Average ratio of punctuation_marks in positive review: 0.1630823626091351\n"
     ]
    }
   ],
   "source": [
    "punctuation_marks = ['...', ',', '?', '!', ':', ';', '\"', '\\'', '-', '.', '–', '—']\n",
    "\n",
    "data['punctuation_marks'] = data['review'].apply(lambda x: sum([1 for x in x if x in punctuation_marks]))\n",
    "show_mean_feature_value_for_both('punctuation_marks', normalize_by_word_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoe6CYO8gH64"
   },
   "source": [
    "Unfortunately this perspective assumption was not justified too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6ObsB2ogH65"
   },
   "source": [
    "#### Difference between positive and negative smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ShJZhAQcgH65",
    "outputId": "6b51c62c-5dc4-41f6-925e-277c432052ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mood in positive review: 0.02376\n",
      "Average mood in negative review: 0.04356\n"
     ]
    }
   ],
   "source": [
    "def mood_counter(text):\n",
    "    braces = 0\n",
    "    \n",
    "    for i in text:\n",
    "    \n",
    "        if i == ')':\n",
    "            braces += 1\n",
    "        \n",
    "        elif i == '(':\n",
    "            braces -= 1\n",
    "    \n",
    "    return braces\n",
    "\n",
    "data['mood'] = data['review'].apply(lambda x: mood_counter(x))\n",
    "show_mean_feature_value_for_both('mood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R69xvvLfgH7A"
   },
   "source": [
    "Values are to small but negative reviews twice more positive than positive reviews)) So we will not delete smile or sad brackets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKbweDB-gH7B"
   },
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Xzgy0xwHggd0",
    "outputId": "46096df1-eaa7-4c8c-d856-814de0a9e06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment in positive review: 0.19473096852005195\n",
      "Average sentiment in negative review: 0.012063536307679767\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['sentiment'] = data['review'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "show_mean_feature_value_for_both('sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GS0DiWJ2gH7E"
   },
   "source": [
    "There is notable difference between senses in these review categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFApwKNhgH7F"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlVVcCaUgH7F"
   },
   "source": [
    "## Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9z8NGhEegH7J"
   },
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSOZbuTcgH7L"
   },
   "source": [
    "## Removing Punctuation\n",
    "\n",
    "Do not forget that we found some relation between class and brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GqX6iAOygH7M"
   },
   "outputs": [],
   "source": [
    "data['review'] = data['review'].str.replace('[^\\w\\s()]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqDzng_kgH7O"
   },
   "source": [
    "## Removing common words\n",
    "\n",
    "Let's find commonly occuring words which may not be in stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "-xVz8cdvgH7P",
    "outputId": "5f978f85-a40a-475d-b87b-52503434f728"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      337527\n",
       "and      173219\n",
       "a        162460\n",
       "of       151395\n",
       "to       130530\n",
       "is       111313\n",
       "in        97710\n",
       "it        75770\n",
       "i         71050\n",
       "this      68775\n",
       "that      66282\n",
       "br        55134\n",
       "as        50168\n",
       "with      45182\n",
       "for       43697\n",
       "was       43145\n",
       "but       39654\n",
       "film      39169\n",
       "movie     35868\n",
       "his       33469\n",
       "on        32938\n",
       "are       29104\n",
       "you       29063\n",
       "he        28232\n",
       "not       27658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_freq = pd.Series(' '.join(data[data['target'] == 1]['review']).split()).value_counts()\n",
    "pos_freq[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "aJjbtCsogH7S",
    "outputId": "59fd6480-46f3-4e82-c014-cd25908a75cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      323438\n",
       "a        156775\n",
       "and      144352\n",
       "of       136593\n",
       "to       135970\n",
       "is        98626\n",
       "in        86167\n",
       "this      80170\n",
       "i         79532\n",
       "it        76151\n",
       "that      69273\n",
       "br        58461\n",
       "was       51989\n",
       "movie     47194\n",
       "for       42556\n",
       "but       41671\n",
       "with      41019\n",
       "as        39707\n",
       "film      34738\n",
       "on        33484\n",
       "not       31465\n",
       "have      30516\n",
       "you       30203\n",
       "are       29001\n",
       "be        28425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_freq = pd.Series(' '.join(data[data['target'] == 0]['review']).split()).value_counts()\n",
    "neg_freq[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceZYcXgBgH7V"
   },
   "source": [
    "First 25 words in both lists are quite similar and we can delete them. But what if not only first 25 are similar? There may be more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7pyXze3dgH7X",
    "outputId": "bf31a192-1f5d-4426-ee2a-2fd5cca6d11c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge lists of 25 common words\n",
    "#common_words = list(pos_freq[:25].index) + list(neg_freq[:25].index)\n",
    "common_words = list(pos_freq[:150].index) + list(neg_freq[:150].index)\n",
    "#remove duplicate elements\n",
    "common_words = list(set(common_words))\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykmMJMFlgH7a"
   },
   "source": [
    "Length 150 means that top-150 words in both categories are the same, length 300 means that top words are completely don't match. Length of the obtained merge list allow us to be sure that the most common words in both categories are almost the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1no_Kj04gH7a"
   },
   "source": [
    "Deleting the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCvxT5MsgH7b"
   },
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in common_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5k70EWWgH7c"
   },
   "source": [
    "## Removing of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myknu-7vgH7d"
   },
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in cachedStopWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2q_mbtTgH7f"
   },
   "source": [
    "## Removing HTML markup and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4Z-3NjugH7h"
   },
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x:  BeautifulSoup(x, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbmkKnZHgH7l"
   },
   "source": [
    "## Splitting the data\n",
    "\n",
    "The default split is 50/50 and now we wil make it 70/30. Don't forget to shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "OZHceWiBx1Mz",
    "outputId": "402e20a0-98c9-4307-ec0d-c8ba45f0212c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>swear_words</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>punctuation_marks</th>\n",
       "      <th>mood</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>reviewers mentioned 1 oz episode youll hooked ...</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>4.739414</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>wonderful production filming technique unassum...</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>thought wonderful spend hot summer weekend sit...</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>4.584337</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically theres family boy (jake) thinks ther...</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>4.427536</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.057813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter matteis money visually stunning mr matt...</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>4.730435</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target  word_count  \\\n",
       "0  reviewers mentioned 1 oz episode youll hooked ...       1         307   \n",
       "1  wonderful production filming technique unassum...       1         162   \n",
       "2  thought wonderful spend hot summer weekend sit...       1         166   \n",
       "3  basically theres family boy (jake) thinks ther...       0         138   \n",
       "4  petter matteis money visually stunning mr matt...       1         230   \n",
       "\n",
       "   avg_word  stopwords  swear_words  numerics  upper  punctuation_marks  mood  \\\n",
       "0  4.739414        122            0         1      8                 58     0   \n",
       "1  5.166667         62            0         0      2                 24     0   \n",
       "2  4.584337         70            0         0      3                 24     0   \n",
       "3  4.427536         58            0         1      3                 19     0   \n",
       "4  4.730435         92            0         0      1                 32     0   \n",
       "\n",
       "   sentiment  \n",
       "0   0.023433  \n",
       "1   0.109722  \n",
       "2   0.354008  \n",
       "3  -0.057813  \n",
       "4   0.217952  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8H1EEsOGgH7m"
   },
   "outputs": [],
   "source": [
    "target = data['target']\n",
    "data.drop(['target'], inplace=True, axis=1)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, \n",
    "                                                                    target, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=target, \n",
    "                                                                    shuffle=True,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sgj01YJMgH7j"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzHwfYBbsgbU"
   },
   "outputs": [],
   "source": [
    "def tokenize(text, stem_not_lem=True):\n",
    "    min_length = 3\n",
    "   \n",
    "    tokenized_words = word_tokenize(text)\n",
    "\n",
    "    if stem_not_lem:\n",
    "        tokens = list(map(lambda token: PorterStemmer().stem(token), tokenized_words))\n",
    "    else:\n",
    "        tokens = list(map(lambda token: WordNetLemmatizer().lemmatize(token), tokenized_words))\n",
    "    \n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filtered_tokens = list(filter(lambda token:\n",
    "                  p.match(token) and len(token)>=min_length,\n",
    "         tokens)); # check if numbers are needed\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "    \n",
    "def vectorize_with_tf_idf(train_data, tokenizer, test_data=None, max_feats=50000):\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenizer, \n",
    "                            #min_df=3,\n",
    "                            #max_df=0.90, \n",
    "                            max_features=max_feats,\n",
    "                            use_idf=True, \n",
    "                            sublinear_tf=True,\n",
    "                            norm='l2',\n",
    "                            ngram_range = (1,3));\n",
    "    \n",
    "    vectorised_train_data = tfidf.fit_transform(train_data)\n",
    "    if test_data is None:\n",
    "        return vectorised_train_data, tfidf\n",
    "    else:\n",
    "        vectorised_test_data = tfidf.transform(test_data)\n",
    "        return vectorised_train_data, vectorised_test_data, tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tkvAl_bdgH7u"
   },
   "source": [
    "## Vectorizing\n",
    "\n",
    "Let's start from 3000 features in tf-idf. Later we will check other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_z66AclSgH7v",
    "outputId": "9be1ff30-1d7f-4c90-88f8-b19c4e4a534d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  35000  samples in the train\n",
      "there are  3000  features in the dataset\n",
      "CPU times: user 3min 25s, sys: 1.29 s, total: 3min 26s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Learn and transform train documents\n",
    "vectorised_train_data, tfidf = vectorize_with_tf_idf(train_data=train_data['review'], \n",
    "                                                                           tokenizer=tokenize,\n",
    "                                                                           max_feats=3000)\n",
    "\n",
    "print('there are ', vectorised_train_data.shape[0], ' samples in the train')\n",
    "num_feats = vectorised_train_data.shape[1]\n",
    "print('there are ', num_feats, ' features in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SFDI6mJMELwG",
    "outputId": "d14c6639-c9ac-4010-e55b-6f68fdfdc30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 3009), (15000, 3009))"
      ]
     },
     "execution_count": 191,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = sparse.hstack((vectorised_train_data, train_data.drop(['review'], axis=1).to_numpy()))\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3WdGOLbgH7r"
   },
   "source": [
    "# Modeling and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Axv8YbigH70"
   },
   "source": [
    "## SGD classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vLACdsPgH70"
   },
   "source": [
    "Now we are finding best parameters for SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "MHEwO6esFevD",
    "outputId": "6da28a68-d69d-4ec7-8e31-0d5ff9afd2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     random_state=None, shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [1e-05, 0.0001, 0.0005, 0.001, 0.01],\n",
       "                         'loss': ['log', 'modified_huber']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 203,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'loss': ['log', 'modified_huber'], \n",
    "              'alpha': [1e-5, 1e-4, 5e-4, 1e-3, 1e-2]}\n",
    "grid_clf = GridSearchCV(SGDClassifier(), parameters, scoring='roc_auc', n_jobs=-1,\n",
    "                   cv=5, verbose=1)\n",
    "\n",
    "grid_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "bnQmf8o_GmOB",
    "outputId": "801fac78-2271-4c49-bf72-2cee3adfba60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'log'}</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>3.563150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'alpha': 0.0005, 'loss': 'modified_huber'}</td>\n",
       "      <td>0.795860</td>\n",
       "      <td>2.957689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'alpha': 0.001, 'loss': 'log'}</td>\n",
       "      <td>0.786721</td>\n",
       "      <td>4.623880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber'}</td>\n",
       "      <td>0.773994</td>\n",
       "      <td>3.169701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'alpha': 0.01, 'loss': 'modified_huber'}</td>\n",
       "      <td>0.773727</td>\n",
       "      <td>2.907726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'alpha': 0.01, 'loss': 'log'}</td>\n",
       "      <td>0.761135</td>\n",
       "      <td>3.866019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'alpha': 1e-05, 'loss': 'log'}</td>\n",
       "      <td>0.754164</td>\n",
       "      <td>3.843386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 1e-05, 'loss': 'modified_huber'}</td>\n",
       "      <td>0.739384</td>\n",
       "      <td>2.605306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'alpha': 0.0005, 'loss': 'log'}</td>\n",
       "      <td>0.731478</td>\n",
       "      <td>3.274979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'modified_huber'}</td>\n",
       "      <td>0.713987</td>\n",
       "      <td>2.544674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  mean_test_score  mean_fit_time\n",
       "2             {'alpha': 0.0001, 'loss': 'log'}         0.819995       3.563150\n",
       "5  {'alpha': 0.0005, 'loss': 'modified_huber'}         0.795860       2.957689\n",
       "6              {'alpha': 0.001, 'loss': 'log'}         0.786721       4.623880\n",
       "7   {'alpha': 0.001, 'loss': 'modified_huber'}         0.773994       3.169701\n",
       "9    {'alpha': 0.01, 'loss': 'modified_huber'}         0.773727       2.907726\n",
       "8               {'alpha': 0.01, 'loss': 'log'}         0.761135       3.866019\n",
       "0              {'alpha': 1e-05, 'loss': 'log'}         0.754164       3.843386\n",
       "1   {'alpha': 1e-05, 'loss': 'modified_huber'}         0.739384       2.605306\n",
       "4             {'alpha': 0.0005, 'loss': 'log'}         0.731478       3.274979\n",
       "3  {'alpha': 0.0001, 'loss': 'modified_huber'}         0.713987       2.544674"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_clf.cv_results_).sort_values('rank_test_score')[['params', 'mean_test_score', 'mean_fit_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XjobZiagH73"
   },
   "source": [
    "The best model have auc roc score near 0,82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_nLN8vVgH73"
   },
   "source": [
    "### Finding best shape of tf-idf matrix\n",
    "\n",
    "Let's make an experiment in which we will find the best shape of tf-idf matrix on the example of the best SGD classifier. The experiment can't guarantee that all the other models will show the same distribution over the considered parameter values but checking all possible feature numbers for all models is very time-consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3HinbZZZgH74",
    "outputId": "2a7e6804-3aa7-4b49-b14e-da41b5776231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num feats: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   10.2s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.83168229 0.7590698  0.76264163 0.74945543 0.80676212] mean: 0.7819222530612245 \n",
      "\n",
      "Num feats: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.8s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.74099037 0.82909151 0.69466931 0.78513216 0.83379453] mean: 0.7767355755102041 \n",
      "\n",
      "Num feats: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.4s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.83289208 0.73151478 0.66328367 0.79500049 0.63923469] mean: 0.7323851428571428 \n",
      "\n",
      "Num feats: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.2s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.66791935 0.62824261 0.84889527 0.63117608 0.76834351] mean: 0.7089153632653062 \n",
      "\n",
      "Num feats: 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    7.3s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.70397494 0.78175273 0.71943771 0.77683224 0.85722531] mean: 0.767844587755102 \n",
      "\n",
      "Num feats: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    5.4s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.84700612 0.85344155 0.85600392 0.61560465 0.69673396] mean: 0.7737580408163265 \n",
      "\n",
      "Num feats: 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.3s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.8647418  0.76899649 0.85778359 0.83966653 0.86082384] mean: 0.8384024489795918 \n",
      "\n",
      "Num feats: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.5s remaining:    4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: [0.67410661 0.80934008 0.54406376 0.86169943 0.85703682] mean: 0.7492493387755103 \n",
      "\n",
      "CPU times: user 20min 12s, sys: 5.16 s, total: 20min 18s\n",
      "Wall time: 21min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_features = [1000, 2000, 3000, 5000, 7000, 10000, 15000, 20000]\n",
    "\n",
    "for feats in num_features:\n",
    "    print('Num feats:', feats)\n",
    "    # Learn and transform train documents\n",
    "    vectorised_train_data, tfidf = vectorize_with_tf_idf(train_data=train_data['review'], \n",
    "                                                        tokenizer=tokenize,\n",
    "                                                        max_feats=3000)\n",
    "\n",
    "    train_features = sparse.hstack((vectorised_train_data, train_data.drop(['review'], axis=1).to_numpy()))\n",
    "\n",
    "    clf = SGDClassifier(loss='log', alpha=0.0001)\n",
    "    score = cross_val_score(estimator=clf, X=train_features, y=train_labels, \n",
    "                            scoring='roc_auc', cv=5, n_jobs=-1, verbose=10)\n",
    "    print('score:', score, 'mean:', score.mean(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGQziO59gH77"
   },
   "source": [
    "With an increase of number of features model becomes better, but after 15000 features profit is very small. So let's deal with 15000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziXRsCAmgH78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Learn and transform train documents\n",
    "vectorised_train_data, vectorised_test_data, tfidf = vectorize_with_tf_idf(train_data=train_data['review'], \n",
    "                                                                           tokenizer=tokenize, \n",
    "                                                                           test_data=test_data['review'],\n",
    "                                                                           max_feats=15000)\n",
    "\n",
    "train_features = sparse.hstack((vectorised_train_data, train_data.drop(['review'], axis=1).to_numpy()))\n",
    "test_features = sparse.hstack((vectorised_test_data, test_data.drop(['review'], axis=1).to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "g1bvx3eHgH7-"
   },
   "source": [
    "## Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "hidden": true,
    "id": "8lay5DnkVSDq",
    "outputId": "b4117932-a419-4e09-883c-8e81a8a7fa09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 31.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 31.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.56130676, 0.56464014, 0.5632183 ])"
      ]
     },
     "execution_count": 235,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=SVC(), X=train_features, y=train_labels,\n",
    "                scoring='roc_auc', cv=3, n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Ycjd08rdgH8B"
   },
   "source": [
    "Computational time of this method is very long and the results are worse than SGD model gave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "Xe1ga7pzgH8C"
   },
   "source": [
    "## Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "hidden": true,
    "id": "q1HeRHhZSJnS",
    "outputId": "9188e79a-d168-4df9-e1bc-3e1a4415fc51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                                   fit_prior=True),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [1e-05, 0.0001, 0.0005, 0.001, 0.01, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'alpha': [1e-5, 1e-4, 5e-4, 1e-3, 1e-2, 1e-1]}\n",
    "grid_clf = GridSearchCV(BernoulliNB(), parameters, scoring='roc_auc', n_jobs=-1,\n",
    "                   cv=5, verbose=1)\n",
    "\n",
    "grid_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "hidden": true,
    "id": "45VKTenwSJnl",
    "outputId": "2009e802-111b-45b9-f9f3-812bcce1ba0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.925376</td>\n",
       "      <td>0.078896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.925127</td>\n",
       "      <td>0.085312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.924686</td>\n",
       "      <td>0.076159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 0.0005}</td>\n",
       "      <td>0.924516</td>\n",
       "      <td>0.078539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>0.924127</td>\n",
       "      <td>0.078545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>0.923534</td>\n",
       "      <td>0.090075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              params  mean_test_score  mean_fit_time\n",
       "5     {'alpha': 0.1}         0.925376       0.078896\n",
       "4    {'alpha': 0.01}         0.925127       0.085312\n",
       "3   {'alpha': 0.001}         0.924686       0.076159\n",
       "2  {'alpha': 0.0005}         0.924516       0.078539\n",
       "1  {'alpha': 0.0001}         0.924127       0.078545\n",
       "0   {'alpha': 1e-05}         0.923534       0.090075"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_clf.cv_results_).sort_values('rank_test_score')[['params', 'mean_test_score', 'mean_fit_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "81Z7uGLWgH8E"
   },
   "source": [
    "Multinomial Naive Bayes have auc roc score about 0.92, that is better than the  score of SGD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "-RJny5mbN5nd"
   },
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "tqP6wnvzN7jr"
   },
   "outputs": [],
   "source": [
    "calib_tr_data, calib_val_data, calib_tr_labels, calib_val_labels = train_test_split(\n",
    "    train_features, \n",
    "    train_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=train_labels, \n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "def clf_fit_show_auc(clf, X_train, y_train, X_test, y_test):\n",
    "    #classifier = OneVsRestClassifier(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob_pred = clf.predict_proba(X_test)[:,1]\n",
    "    print('auc roc score : ', roc_auc_score(y_test, prob_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "mJ7sOdo6MDml",
    "outputId": "2c20ba93-019b-406b-fe4d-d52aed3fc3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc roc score :  0.9261577551020407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "clf = CalibratedClassifierCV(BernoulliNB(), \n",
    "                                    cv=5, \n",
    "                                    method='isotonic')\n",
    "\n",
    "\n",
    "clf_fit_show_auc(clf, calib_tr_data, calib_tr_labels, calib_val_data, calib_val_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "ElbBQlBDP0_C"
   },
   "source": [
    "Almost the same score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsEZcgYdgH8E"
   },
   "source": [
    "## TruncatedSVD\n",
    "\n",
    "Now let's try to reduce dimension of tf-idf sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I37yiD4PgH8F"
   },
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgP0cTqjgH8G"
   },
   "source": [
    "Let's make a pipeline to make data preprocessing easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YopvFBXxgH8G"
   },
   "outputs": [],
   "source": [
    "preprocessing = Pipeline(steps = [('tsvd', tsvd)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZ79I1bngH8J"
   },
   "source": [
    "We will estimate the efficiency of the decomposition on the example of Naive Bayes classifier with the best parameters we found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-DmiilwkgH8K",
    "outputId": "9f5aba25-a0fd-4581-a180-636d1ee2d57d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  3.6min remaining:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 80.2 ms, total: 320 ms\n",
      "Wall time: 4min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.6min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = BernoulliNB(alpha=0.1)\n",
    "tsvd_clf_pipe = Pipeline(steps=[('preprocessing', preprocessing), ('clf', clf)])\n",
    "\n",
    "scores  = cross_val_score(estimator=tsvd_clf_pipe, X=train_features, y=train_labels,\n",
    "                scoring='roc_auc', cv=5, n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HJfUxuqbTHtO",
    "outputId": "1aa9b770-898e-41df-f4fb-f9c782f2b45b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87044139, 0.86681535, 0.88100669, 0.87774343, 0.87346212])"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M934rTUcgH8N"
   },
   "source": [
    "Reducing the dimension of the matrix didn't make a profit but take more time than fitting without SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2k4tGD1rtCp3"
   },
   "outputs": [],
   "source": [
    "do_nothing_tf = FunctionTransformer(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oWa6mEetaav"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=15000,\n",
       "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function tokenize at 0x00000249FB07CBF8>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSloYbX0qpri"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('transformer',  make_column_transformer((tfidf, 'review'),\n",
    "                                             remainder='passthrough' # the same as(do_nothing_tf, [item for item in list(train_data.columns) if item!='review']),\n",
    "                                            )\n",
    "    ),\n",
    "    ('clf', BernoulliNB(alpha=0.1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 10), pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NyVPLNaQkkQN",
    "outputId": "09c98a28-5e20-4bb1-8c3a-029767bf7cd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239850933333333\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pipeline.fit(train_data, train_labels)\n",
    "preds = pipeline.predict_proba(test_data)\n",
    "score = roc_auc_score(test_labels, preds[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5njR6jNgH8O"
   },
   "source": [
    "# Visualization\n",
    "Let's try to visualise the text part of the best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUkc3UfzgH8O"
   },
   "outputs": [],
   "source": [
    "TextExpl = TextExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=15000,\n",
       "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function tokenize at 0x00000249FB07CBF8>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WuIL-XBv4Lml",
    "outputId": "78287e63-1be5-4330-9814-ad22bdacf865"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aamir',\n",
       " 'aaron',\n",
       " 'abandon',\n",
       " 'abba',\n",
       " 'abbey',\n",
       " 'abbi',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbott costello',\n",
       " 'abc']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_tfidf = pipeline.named_steps['preprocessing'].named_steps['tfidf'].get_feature_names()\n",
    "feature_names_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline(steps=[('tfidf', tfidf)])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessing', preprocessing), \n",
    "                           ('clf', BernoulliNB(alpha=0.1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_data, test_text_data = train_data['review'], test_data['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209163822222224\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pipeline.fit(train_text_data, train_labels)\n",
    "preds = pipeline.predict_proba(test_text_data)\n",
    "score = roc_auc_score(test_labels, preds[:, 1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ph2CjEDgH8P"
   },
   "source": [
    "#### Let's find some presentative positive text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "OWsYdlSNgH8P",
    "outputId": "99c23a77-9a43-4cc0-ea67-4a4a4a231a54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of very positive sentense: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class: 1\n",
      "Predicted: [1.22074607e-07 9.99999878e-01]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, test_text_data.shape[0])):\n",
    "    if (preds[i, 1] > 0.97) and i!=6: # i=6 is not interesting\n",
    "        positive_index = i\n",
    "        print('index of very positive sentense:', positive_index)\n",
    "        break\n",
    "\n",
    "pos_text = test_text_data.values[positive_index]\n",
    "        \n",
    "print('Real class:', list(test_labels)[positive_index])\n",
    "print('Predicted:', preds[positive_index, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=aaron\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>14.038</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +14.182\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.144\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"opacity: 0.80\">believe </span><span style=\"background-color: hsl(120, 100.00%, 84.63%); opacity: 0.85\" title=\"0.211\">john</span><span style=\"opacity: 0.80\"> died filming </span><span style=\"background-color: hsl(120, 100.00%, 91.31%); opacity: 0.82\" title=\"0.093\">episode</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.92%); opacity: 0.82\" title=\"0.099\">collapsed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.13%); opacity: 0.84\" title=\"0.146\">set</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.52%); opacity: 0.83\" title=\"-0.139\">read</span><span style=\"opacity: 0.80\"> (out </span><span style=\"background-color: hsl(120, 100.00%, 82.67%); opacity: 0.86\" title=\"0.250\">biography</span><span style=\"opacity: 0.80\"> online)</span><span style=\"background-color: hsl(120, 100.00%, 78.33%); opacity: 0.88\" title=\"0.344\">john</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.60%); opacity: 0.90\" title=\"0.408\">ritter</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.90%); opacity: 0.90\" title=\"0.401\">born</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.78%); opacity: 0.83\" title=\"0.134\">burbank</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.40%); opacity: 0.82\" title=\"0.077\">calafornia</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.88%); opacity: 0.93\" title=\"0.551\">september</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.52%); opacity: 0.81\" title=\"0.036\">17th</span><span style=\"opacity: 0.80\"> 1948 </span><span style=\"background-color: hsl(120, 100.00%, 91.99%); opacity: 0.82\" title=\"0.083\">landed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.74%); opacity: 0.82\" title=\"0.087\">last</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.57%); opacity: 0.84\" title=\"0.174\">television</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.92%); opacity: 0.89\" title=\"0.377\">role</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.030\">8</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.86%); opacity: 0.88\" title=\"0.332\">simple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.98%); opacity: 0.82\" title=\"0.069\">rules</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.89%); opacity: 0.84\" title=\"0.150\">dating</span><span style=\"opacity: 0.80\"> teenage daughter (</span><span style=\"background-color: hsl(120, 100.00%, 89.09%); opacity: 0.83\" title=\"0.129\">2002</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 74.89%); opacity: 0.90\" title=\"0.425\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.55%); opacity: 0.88\" title=\"0.317\">popular</span><span style=\"opacity: 0.80\"> book sitcom </span><span style=\"background-color: hsl(120, 100.00%, 93.07%); opacity: 0.82\" title=\"0.068\">played</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.35%); opacity: 0.88\" title=\"0.344\">paul</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.49%); opacity: 0.81\" title=\"0.037\">hennessey</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.48%); opacity: 0.94\" title=\"0.562\">loving</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.93%); opacity: 0.81\" title=\"0.043\">yet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.56%); opacity: 0.83\" title=\"-0.138\">rational</span><span style=\"opacity: 0.80\"> dad </span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.043\">laid</span><span style=\"opacity: 0.80\"> ground </span><span style=\"background-color: hsl(120, 100.00%, 92.98%); opacity: 0.82\" title=\"0.069\">rules</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.69%); opacity: 0.84\" title=\"0.153\">three</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.63%); opacity: 0.90\" title=\"0.431\">children</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.017\">ratings</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.31%); opacity: 0.90\" title=\"0.415\">winner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.18%); opacity: 0.89\" title=\"0.371\">season</span><span style=\"opacity: 0.80\"> peoples </span><span style=\"background-color: hsl(120, 100.00%, 84.11%); opacity: 0.85\" title=\"0.221\">choice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.72%); opacity: 0.88\" title=\"0.313\">award</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.08%); opacity: 0.84\" title=\"0.183\">comedy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.827\">favorite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.09%); opacity: 0.83\" title=\"0.129\">comedy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.01%); opacity: 0.83\" title=\"0.131\">series</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.67%); opacity: 0.88\" title=\"0.314\">family</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.32%); opacity: 0.88\" title=\"0.322\">awards</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.73%); opacity: 0.85\" title=\"0.209\">working</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.89%); opacity: 0.81\" title=\"0.056\">8</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.86%); opacity: 0.88\" title=\"0.332\">simple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.98%); opacity: 0.82\" title=\"0.069\">rules</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.38%); opacity: 0.81\" title=\"0.038\">starred</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.47%); opacity: 0.82\" title=\"0.091\">secondtolast</span><span style=\"opacity: 0.80\"> manhood (2003)br year </span><span style=\"background-color: hsl(120, 100.00%, 84.63%); opacity: 0.85\" title=\"0.211\">john</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.44%); opacity: 0.81\" title=\"0.026\">rehearsing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.44%); opacity: 0.81\" title=\"0.026\">4th</span><span style=\"opacity: 0.80\"> (3rd </span><span style=\"background-color: hsl(120, 100.00%, 89.01%); opacity: 0.83\" title=\"0.131\">series</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 91.31%); opacity: 0.82\" title=\"0.093\">episode</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.030\">8</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.86%); opacity: 0.88\" title=\"0.332\">simple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.98%); opacity: 0.82\" title=\"0.069\">rules</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 85.67%); opacity: 0.85\" title=\"0.191\">now</span><span style=\"opacity: 0.80\"> shortened) </span><span style=\"background-color: hsl(0, 100.00%, 93.55%); opacity: 0.81\" title=\"-0.061\">fell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.91%); opacity: 0.83\" title=\"-0.116\">ill</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.97%); opacity: 0.89\" title=\"0.376\">henry</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.50%); opacity: 0.82\" title=\"0.091\">winkler</span><span style=\"opacity: 0.80\"> described </span><span style=\"background-color: hsl(120, 100.00%, 84.63%); opacity: 0.85\" title=\"0.211\">john</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.93%); opacity: 0.84\" title=\"-0.149\">looked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.55%); opacity: 0.85\" title=\"0.193\">food</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.57%); opacity: 0.84\" title=\"0.174\">poisoningthen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.92%); opacity: 0.82\" title=\"0.099\">collapsed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.13%); opacity: 0.84\" title=\"0.146\">set</span><span style=\"opacity: 0.80\"> quickly rushed nearby hospital </span><span style=\"background-color: hsl(120, 100.00%, 88.78%); opacity: 0.83\" title=\"0.134\">burbank</span><span style=\"opacity: 0.80\"> hospital </span><span style=\"background-color: hsl(120, 100.00%, 75.90%); opacity: 0.90\" title=\"0.401\">born</span><span style=\"opacity: 0.80\"> diagnosed aorta </span><span style=\"background-color: hsl(120, 100.00%, 78.95%); opacity: 0.88\" title=\"0.330\">dissection</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.038\">unrecognized</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.41%); opacity: 0.86\" title=\"0.256\">heart</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.61%); opacity: 0.85\" title=\"0.211\">flaw</span><span style=\"opacity: 0.80\"> underwent </span><span style=\"background-color: hsl(0, 100.00%, 80.86%); opacity: 0.87\" title=\"-0.288\">surgery</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.33%); opacity: 0.88\" title=\"0.344\">john</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.60%); opacity: 0.90\" title=\"0.408\">ritter</span><span style=\"opacity: 0.80\"> died </span><span style=\"background-color: hsl(120, 100.00%, 81.85%); opacity: 0.86\" title=\"0.267\">age</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.45%); opacity: 0.81\" title=\"0.026\">54</span><span style=\"opacity: 0.80\"> 1 week away 55th </span><span style=\"background-color: hsl(120, 100.00%, 86.36%); opacity: 0.84\" title=\"0.178\">birthday</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.06%); opacity: 0.80\" title=\"0.004\">leaving</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.30%); opacity: 0.86\" title=\"0.258\">wife</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.53%); opacity: 0.82\" title=\"-0.090\">amy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.41%); opacity: 0.81\" title=\"0.050\">yasbeck</span><span style=\"opacity: 0.80\"> 4 </span><span style=\"background-color: hsl(120, 100.00%, 81.35%); opacity: 0.87\" title=\"0.278\">children</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TextExpl.fit(pos_text, pipeline.predict_proba)\n",
    "display(TextExpl.show_prediction(target_names=feature_names_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMsJfOLvgH8Z"
   },
   "source": [
    "Here we can see such words as favorite, winner, award, loving etc. These words are charachterize this review as positive with probability of 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jfOs7DkgH8a"
   },
   "source": [
    "#### Let's find some negative text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRBaEhL8gH8a",
    "outputId": "f688e1a7-3f57-4945-ceae-e514a338b3f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of very negative sentense: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class: 0\n",
      "Predicted: [9.99989927e-01 1.00727274e-05]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, test_text_data.shape[0])):\n",
    "    if (preds[i, 0] > 0.97) and i!=0: #i=0 is very short\n",
    "        negative_index = i\n",
    "        print('index of very negative sentense:', negative_index)\n",
    "        break\n",
    "\n",
    "neg_text = test_text_data.values[negative_index]\n",
    "        \n",
    "print('Real class:', list(test_labels)[negative_index])\n",
    "print('Predicted:', preds[negative_index, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REzRBZc6gH8c",
    "outputId": "1072ef8f-cf2b-4d0d-8870-533588a924d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=aamir\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>-10.610</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +10.501\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.108\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 86.32%); opacity: 0.84\" title=\"-0.250\">hilariously</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.78%); opacity: 0.92\" title=\"0.669\">obvious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.97%); opacity: 0.82\" title=\"0.138\">drama</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.79%); opacity: 0.88\" title=\"0.437\">bunch</span><span style=\"opacity: 0.80\"> high </span><span style=\"background-color: hsl(120, 100.00%, 85.81%); opacity: 0.85\" title=\"0.264\">school</span><span style=\"opacity: 0.80\"> (i </span><span style=\"background-color: hsl(120, 100.00%, 86.94%); opacity: 0.84\" title=\"0.234\">think</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 94.93%); opacity: 0.81\" title=\"0.061\">kids</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.93%); opacity: 0.90\" title=\"-0.561\">enjoy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.08%); opacity: 0.84\" title=\"-0.257\">nonstop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.81%); opacity: 0.90\" title=\"-0.565\">hiphop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.07%); opacity: 0.80\" title=\"-0.015\">break</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.26%); opacity: 0.83\" title=\"-0.154\">dancing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.50%); opacity: 0.83\" title=\"0.195\">graffiti</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.80%); opacity: 0.85\" title=\"0.291\">trying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.78%); opacity: 0.84\" title=\"-0.213\">become</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.49%); opacity: 0.81\" title=\"-0.051\">dj</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.97%); opacity: 0.80\" title=\"0.006\">roxyor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.78%); opacity: 0.87\" title=\"0.407\">totally</span><span style=\"opacity: 0.80\"> honest </span><span style=\"background-color: hsl(120, 100.00%, 76.23%); opacity: 0.90\" title=\"0.551\">bored</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.03%); opacity: 0.84\" title=\"0.232\">forgot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.65%); opacity: 0.83\" title=\"-0.168\">music</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.09%); opacity: 0.82\" title=\"0.114\">agree</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.159\">terribly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.33%); opacity: 0.83\" title=\"0.153\">acted</span><span style=\"opacity: 0.80\"> andas </span><span style=\"background-color: hsl(0, 100.00%, 96.95%); opacity: 0.81\" title=\"-0.029\">dramafailed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.44%); opacity: 0.88\" title=\"0.479\">dismally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.38%); opacity: 0.89\" title=\"0.513\">supposed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.11%); opacity: 0.82\" title=\"0.114\">kids</span><span style=\"opacity: 0.80\"> likable nice </span><span style=\"background-color: hsl(120, 100.00%, 89.55%); opacity: 0.83\" title=\"0.170\">found</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.97%); opacity: 0.90\" title=\"0.593\">bland</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.07%); opacity: 0.95\" title=\"0.877\">boring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.59%); opacity: 0.84\" title=\"0.243\">hated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.85%); opacity: 0.94\" title=\"-0.811\">ramon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.95%); opacity: 0.80\" title=\"-0.017\">graffiti</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.78%); opacity: 0.84\" title=\"-0.238\">subway</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.93%); opacity: 0.82\" title=\"-0.139\">trains</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.09%); opacity: 0.87\" title=\"0.428\">looked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.45%); opacity: 0.80\" title=\"0.023\">upon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.20%); opacity: 0.96\" title=\"0.911\">excuse</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.033\">hes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.79%); opacity: 0.82\" title=\"-0.142\">defacing</span><span style=\"opacity: 0.80\"> public property </span><span style=\"background-color: hsl(120, 100.00%, 81.70%); opacity: 0.87\" title=\"0.379\">isnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.68%); opacity: 0.80\" title=\"0.020\">begin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.11%); opacity: 0.82\" title=\"0.114\">kids</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.29%); opacity: 0.82\" title=\"-0.131\">tap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.68%); opacity: 0.85\" title=\"-0.267\">citys</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.51%); opacity: 0.83\" title=\"0.195\">electricity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.29%); opacity: 0.81\" title=\"-0.072\">hold</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.24%); opacity: 0.83\" title=\"0.155\">big</span><span style=\"opacity: 0.80\"> dance </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.047\">party</span><span style=\"opacity: 0.80\"> abandoned building uh </span><span style=\"background-color: hsl(120, 100.00%, 74.35%); opacity: 0.91\" title=\"0.614\">huh</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.34%); opacity: 0.91\" title=\"0.615\">supposed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.79%); opacity: 0.88\" title=\"0.437\">bunch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.52%); opacity: 0.81\" title=\"-0.068\">law</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.34%); opacity: 0.83\" title=\"-0.175\">breakers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.04%); opacity: 0.95\" title=\"-0.841\">lovable</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.53%); opacity: 0.92\" title=\"-0.713\">funbr</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.86%); opacity: 0.81\" title=\"-0.062\">forgive</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.65%); opacity: 0.83\" title=\"-0.168\">music</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.68%); opacity: 0.81\" title=\"-0.065\">stand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.81%); opacity: 0.82\" title=\"0.100\">hip</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.21%); opacity: 0.83\" title=\"-0.178\">hop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.56%); opacity: 0.85\" title=\"-0.297\">songs</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.60%); opacity: 0.82\" title=\"-0.125\">wereat</span><span style=\"opacity: 0.80\"> bestmediocre nonstop </span><span style=\"background-color: hsl(120, 100.00%, 85.63%); opacity: 0.85\" title=\"0.269\">theyre</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.57%); opacity: 0.86\" title=\"-0.325\">always</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.51%); opacity: 0.80\" title=\"-0.022\">playing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.58%); opacity: 0.82\" title=\"0.125\">got</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.80%); opacity: 0.83\" title=\"0.188\">point</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.76%); opacity: 0.99\" title=\"1.087\">fastforwarding</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.38%); opacity: 0.93\" title=\"0.754\">endless</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.76%); opacity: 0.81\" title=\"-0.047\">music</span><span style=\"opacity: 0.80\"> numbers (</span><span style=\"background-color: hsl(120, 100.00%, 80.43%); opacity: 0.87\" title=\"0.417\">cut</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.83%); opacity: 0.81\" title=\"-0.062\">music</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.49%); opacity: 0.81\" title=\"0.036\">haver</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.05%); opacity: 0.81\" title=\"0.076\">30</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.95%); opacity: 0.87\" title=\"0.432\">minute</span><span style=\"opacity: 0.80\"> moviemaybe) </span><span style=\"background-color: hsl(120, 100.00%, 96.49%); opacity: 0.81\" title=\"0.036\">imaginative</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.67%); opacity: 0.80\" title=\"-0.020\">numbersthe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.79%); opacity: 0.81\" title=\"-0.063\">subway</span><span style=\"opacity: 0.80\"> dance </span><span style=\"background-color: hsl(0, 100.00%, 93.81%); opacity: 0.81\" title=\"-0.081\">fight</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.81%); opacity: 0.81\" title=\"-0.081\">truly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.77%); opacity: 0.81\" title=\"0.063\">funny</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.79%); opacity: 0.85\" title=\"0.291\">santa</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.19%); opacity: 0.84\" title=\"-0.203\">number</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.69%); opacity: 0.90\" title=\"-0.603\">climatic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.15%); opacity: 0.82\" title=\"0.113\">roxy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.81%); opacity: 0.82\" title=\"0.100\">hip</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.60%); opacity: 0.81\" title=\"-0.066\">hop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.85%); opacity: 0.85\" title=\"0.290\">heres</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.54%); opacity: 0.88\" title=\"0.445\">youre</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.16%); opacity: 0.88\" title=\"0.456\">looking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.24%); opacity: 0.81\" title=\"-0.055\">drama</span><span style=\"opacity: 0.80\"> mixed </span><span style=\"background-color: hsl(120, 100.00%, 95.13%); opacity: 0.81\" title=\"0.057\">inforget</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.85%); opacity: 0.82\" title=\"0.099\">pg</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.16%); opacity: 0.84\" title=\"0.203\">rating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.33%); opacity: 0.83\" title=\"0.175\">theres</span><span style=\"opacity: 0.80\"> incredible </span><span style=\"background-color: hsl(120, 100.00%, 92.30%); opacity: 0.82\" title=\"0.110\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.05%); opacity: 0.85\" title=\"0.312\">swearing</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TextExpl.fit(neg_text, pipeline.predict_proba)\n",
    "display(TextExpl.show_prediction(target_names=feature_names_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2UwUSDQgH8e"
   },
   "source": [
    "And here we see the words terribly, boring, endless, obvious."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW4_edited.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
