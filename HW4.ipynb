{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_edited.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HhA6jSmagH5e"
      },
      "source": [
        "# Installing the needed libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2AehcFQr6ET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "301309a5-cc56-4f25-c3f5-0bc5b1a8669c"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao5khs6Wrclt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fd4c757b-0f34-4aa7-d953-8b822e004143"
      },
      "source": [
        "import nltk\n",
        "nltk.download(['stopwords', 'punkt', 'wordnet'])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH9donQlSOh9",
        "colab_type": "text"
      },
      "source": [
        "# Loading needed libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qMuQFLjZgH5g",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "from sklearn.decomposition import IncrementalPCA as iPCA, TruncatedSVD\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        " \n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "\n",
        "from collections import Counter\n",
        "import string\n",
        "from textblob import TextBlob, Word\n",
        "from random import shuffle\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from eli5.lime import TextExplainer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
        "from tempfile import mkdtemp\n",
        "from shutil import rmtree\n",
        "from sklearn.externals.joblib import Memory"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eeiQyXv_gH5n"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-9ciVPxZgsB",
        "colab_type": "text"
      },
      "source": [
        "Download https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews  \n",
        "Files->Upload to session storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx3Oy67GcBKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "45948b10-fb15-4eb7-fd46-5072b4646cc2"
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLGcD-KojbAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dde14741-3498-4972-f2a6-67a89b85a628"
      },
      "source": [
        "data.rename(columns={'sentiment': 'target'}, inplace=True)\n",
        "data['target'].replace({'positive': 1, 'negative': 0}, inplace=True)\n",
        "data.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  target\n",
              "0  One of the other reviewers has mentioned that ...       1\n",
              "1  A wonderful little production. <br /><br />The...       1\n",
              "2  I thought this was a wonderful way to spend ti...       1\n",
              "3  Basically there's a family where a little boy ...       0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWeO8b6TcMGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "df228f9f-4d44-4498-b591-eb59a8d9115f"
      },
      "source": [
        "data['target'].value_counts()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wgktDBHOgH6H"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffdQD5DNcy4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_mean_feature_value_for_both(col, normalize_by_word_count=False):\n",
        "    print('Average {} in positive review: {}'.format(col, data[data['target'] == 1][col].mean()))\n",
        "    print('Average {} in negative review: {}'.format(col, data[data['target'] == 0][col].mean()))\n",
        "    if normalize_by_word_count:\n",
        "        print('Average ratio of {} in positive review: {}'.format(col, data[data['target'] == 1][col].mean() / data[data['target'] == 1]['word_count'].mean()))\n",
        "        print('Average ratio of {} in positive review: {}'.format(col, data[data['target'] == 0][col].mean() / data[data['target'] == 0]['word_count'].mean()))"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i-7z-lLHgH6I"
      },
      "source": [
        "#### Number of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDlUcLYygH6K"
      },
      "source": [
        "Check if number of words in review can predict the grade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qAnERKOdy7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00df8496-5569-451a-f6c9-ed011ba8b7e9"
      },
      "source": [
        "data['word_count'] = data['review'].apply(lambda x: len(str(x).split(\" \")))\n",
        "show_mean_feature_value_for_both('word_count')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average word_count in positive review: 232.83776\n",
            "Average word_count in negative review: 229.45412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgRsT7hlgH6P"
      },
      "source": [
        "For negative and positive comments number of words is almost identical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgmVUTwxgH6R"
      },
      "source": [
        "#### Average word length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "flTc1U1UgH6R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a503a8d-ba54-4687-8621-4329d33c6add"
      },
      "source": [
        "def avg_word(review):\n",
        "    words = review.split()\n",
        "    return (sum(len(word) for word in words)/len(words))\n",
        "\n",
        "data['avg_word'] = data['review'].apply(lambda x: avg_word(x))\n",
        "show_mean_feature_value_for_both('avg_word')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average avg_word in positive review: 4.657891605718916\n",
            "Average avg_word in negative review: 4.623460730501129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yBrCvcQWgH6W"
      },
      "source": [
        "There is no difference here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x6zkxIvwgH6X"
      },
      "source": [
        "#### Number of stopwords\n",
        "\n",
        "Before changing and removing the stopwords let's try to find some patterns with default list of stopwords from NLTK library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPNi8q8JfAlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "69005f07-39ba-4d35-d93b-148d578c7ede"
      },
      "source": [
        "data['stopwords'] = data['review'].apply(lambda x: len([x for x in x.split() if x in cachedStopWords]))\n",
        "show_mean_feature_value_for_both('stopwords', normalize_by_word_count=True)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average stopwords in positive review: 95.5394\n",
            "Average stopwords in negative review: 93.99816\n",
            "Average ratio of stopwords in positive review: 0.41032605707940156\n",
            "Average ratio of stopwords in positive review: 0.40965993550257457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0uUVVZZsgH6d"
      },
      "source": [
        "And now there is nothing notable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TJ7Hun2lgH6e"
      },
      "source": [
        "#### Number of swear words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsd76RIYfVWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a398e783-98db-466f-9643-16d737a4223e"
      },
      "source": [
        "#collecting swear words (shifted to the right) and present them in two cases: low and with capital letter\n",
        "swear_words=[                                                                                                                                                                                       'Bastard', 'Beaver', 'Bellend', 'Bloodclaat', 'Clunge', 'Cock', 'Dick', 'Dickhead', 'Fanny', 'Flaps', 'Gash', 'Knob', 'Minge', 'Prick', 'Punani', 'Pussy', 'Snatch', 'Twat', 'Cunt', 'Fuck', 'Motherfucker', 'Arsehole', 'Balls', 'Bint', 'Bitch', 'Bollocks', 'Bullshit', 'Feck', 'Munter', 'pissed off', 'Shit', 'Son of a bitch', 'Tits']\n",
        "swear_words += [word.lower() for word in swear_words]\n",
        "\n",
        "data['swear_words'] = data['review'].apply(lambda x: len([x for x in x.split() if x in swear_words]))\n",
        "show_mean_feature_value_for_both('swear_words', normalize_by_word_count=True)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average swear_words in positive review: 0.01476\n",
            "Average swear_words in negative review: 0.01728\n",
            "Average ratio of swear_words in positive review: 6.339177975256248e-05\n",
            "Average ratio of swear_words in positive review: 7.53091729187517e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MSTcxXUWgH6j"
      },
      "source": [
        "Both categories have similar frequencies (very small) of swear words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rxVs0fnagH6k"
      },
      "source": [
        "#### Number of numerics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buu4d-7DfzP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b7026df3-400a-4cd4-d758-748788f542d5"
      },
      "source": [
        "data['numerics'] = data['review'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "show_mean_feature_value_for_both('numerics', normalize_by_word_count=True)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average numerics in positive review: 0.52252\n",
            "Average numerics in negative review: 0.61912\n",
            "Average ratio of numerics in positive review: 0.002244137720617137\n",
            "Average ratio of numerics in positive review: 0.0026982300426769412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lS0cLH2HgH6p"
      },
      "source": [
        "Parts of numerics in reviews are small and that there is no visible differense betweed categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3aWkJtYPgH6r"
      },
      "source": [
        "#### Number of Uppercase words (CAPS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKkVszpWgAdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9d7d731d-961f-458e-c996-194f434a9a22"
      },
      "source": [
        "data['upper'] = data['review'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "show_mean_feature_value_for_both('upper', normalize_by_word_count=True)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average upper in positive review: 4.56928\n",
            "Average upper in negative review: 5.14632\n",
            "Average ratio of upper in positive review: 0.019624308359606275\n",
            "Average ratio of upper in positive review: 0.02242853604023323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8EY2C8xOgH6y"
      },
      "source": [
        "And now there is nothing suspicious"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1A_wXTG2gH6z"
      },
      "source": [
        "#### Number of punctuation marks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbt5G9logJGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a2646053-86df-4997-c9fa-b08cf4ccea60"
      },
      "source": [
        "punctuation_marks = ['...', ',', '?', '!', ':', ';', '\"', '\\'', '-', '.', '–', '—']\n",
        "\n",
        "data['punctuation_marks'] = data['review'].apply(lambda x: sum([1 for x in x if x in punctuation_marks]))\n",
        "show_mean_feature_value_for_both('punctuation_marks', normalize_by_word_count=True)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average punctuation_marks in positive review: 36.09288\n",
            "Average punctuation_marks in negative review: 37.41992\n",
            "Average ratio of punctuation_marks in positive review: 0.15501300132761972\n",
            "Average ratio of punctuation_marks in positive review: 0.1630823626091351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uoe6CYO8gH64"
      },
      "source": [
        "Unfortunately this perspective assumption was not justified too"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o6ObsB2ogH65"
      },
      "source": [
        "#### Difference between positive and negative smiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ShJZhAQcgH65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0903d8f9-88bc-4a88-bf45-999f79f59d90"
      },
      "source": [
        "def mood_counter(text):\n",
        "    braces = 0\n",
        "    \n",
        "    for i in text:\n",
        "    \n",
        "        if i == ')':\n",
        "            braces += 1\n",
        "        \n",
        "        elif i == '(':\n",
        "            braces -= 1\n",
        "    \n",
        "    return braces\n",
        "\n",
        "data['mood'] = data['review'].apply(lambda x: mood_counter(x))\n",
        "show_mean_feature_value_for_both('mood')"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average mood in positive review: 0.02376\n",
            "Average mood in negative review: 0.04356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R69xvvLfgH7A"
      },
      "source": [
        "Values are to small but negative reviews twice more positive than positive reviews)) So we will not delete smile or sad brackets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yKbweDB-gH7B"
      },
      "source": [
        "#### Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzgy0xwHggd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ce62c586-5624-47aa-e055-f5795430562a"
      },
      "source": [
        "%%time\n",
        "\n",
        "data['sentiment'] = data['review'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "show_mean_feature_value_for_both('sentiment')"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average sentiment in positive review: 0.19473096852005084\n",
            "Average sentiment in negative review: 0.012063536307679774\n",
            "CPU times: user 1min 29s, sys: 22.7 ms, total: 1min 30s\n",
            "Wall time: 1min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GS0DiWJ2gH7E"
      },
      "source": [
        "There is notable difference between senses in these review categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UFApwKNhgH7F"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hlVVcCaUgH7F"
      },
      "source": [
        "## Lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9z8NGhEegH7J",
        "colab": {}
      },
      "source": [
        "data['review'] = data['review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jSOZbuTcgH7L"
      },
      "source": [
        "## Removing Punctuation\n",
        "\n",
        "Do not forget that we found some relation between class and brackets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GqX6iAOygH7M",
        "colab": {}
      },
      "source": [
        "data['review'] = data['review'].str.replace('[^\\w\\s()]','')"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MqDzng_kgH7O"
      },
      "source": [
        "## Removing common words\n",
        "\n",
        "Let's find commonly occuring words which may not be in stopword list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xVz8cdvgH7P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "b5398e33-4456-44c1-af38-c47b894a9f82"
      },
      "source": [
        "pos_freq = pd.Series(' '.join(data[data['target'] == 1]['review']).split()).value_counts()\n",
        "pos_freq[:25]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the      337527\n",
              "and      173219\n",
              "a        162460\n",
              "of       151395\n",
              "to       130530\n",
              "is       111313\n",
              "in        97710\n",
              "it        75770\n",
              "i         71050\n",
              "this      68775\n",
              "that      66282\n",
              "br        55134\n",
              "as        50168\n",
              "with      45182\n",
              "for       43697\n",
              "was       43145\n",
              "but       39654\n",
              "film      39169\n",
              "movie     35868\n",
              "his       33469\n",
              "on        32938\n",
              "are       29104\n",
              "you       29063\n",
              "he        28232\n",
              "not       27658\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJjbtCsogH7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4a69ed01-6291-4893-e223-6f0fee32b9ed"
      },
      "source": [
        "neg_freq = pd.Series(' '.join(data[data['target'] == 0]['review']).split()).value_counts()\n",
        "neg_freq[:25]"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the      323438\n",
              "a        156775\n",
              "and      144352\n",
              "of       136593\n",
              "to       135970\n",
              "is        98626\n",
              "in        86167\n",
              "this      80170\n",
              "i         79532\n",
              "it        76151\n",
              "that      69273\n",
              "br        58461\n",
              "was       51989\n",
              "movie     47194\n",
              "for       42556\n",
              "but       41671\n",
              "with      41019\n",
              "as        39707\n",
              "film      34738\n",
              "on        33484\n",
              "not       31465\n",
              "have      30516\n",
              "you       30203\n",
              "are       29001\n",
              "be        28425\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ceZYcXgBgH7V"
      },
      "source": [
        "First 25 words in both lists are quite similar and we can delete them. But what if not only first 25 are similar? There may be more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7pyXze3dgH7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e9a6096-c6c9-45ed-c498-e145f03ec947"
      },
      "source": [
        "#merge lists of 25 common words\n",
        "#common_words = list(pos_freq[:25].index) + list(neg_freq[:25].index)\n",
        "common_words = list(pos_freq[:150].index) + list(neg_freq[:150].index)\n",
        "#remove duplicate elements\n",
        "common_words = list(set(common_words))\n",
        "len(common_words)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ykmMJMFlgH7a"
      },
      "source": [
        "Length 150 means that top-150 words in both categories are the same, length 300 means that top words are completely don't match. Length of the obtained merge list allow us to be sure that the most common words in both categories are almost the same. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1no_Kj04gH7a"
      },
      "source": [
        "Deleting the most common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QCvxT5MsgH7b",
        "colab": {}
      },
      "source": [
        "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in common_words))"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m5k70EWWgH7c"
      },
      "source": [
        "## Removing of Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "myknu-7vgH7d",
        "colab": {}
      },
      "source": [
        "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in cachedStopWords))"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X2q_mbtTgH7f"
      },
      "source": [
        "## Removing HTML markup and metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U4Z-3NjugH7h",
        "colab": {}
      },
      "source": [
        "data['review'] = data['review'].apply(lambda x:  BeautifulSoup(x, 'html.parser').get_text())"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TbmkKnZHgH7l"
      },
      "source": [
        "## Splitting the data\n",
        "\n",
        "The default split is 50/50 and now we wil make it 70/30. Don't forget to shuffle data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZHceWiBx1Mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "88ad41d2-eeea-48f6-8b13-7108ed338c62"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>target</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>swear_words</th>\n",
              "      <th>numerics</th>\n",
              "      <th>upper</th>\n",
              "      <th>punctuation_marks</th>\n",
              "      <th>mood</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reviewers mentioned 1 oz episode youll hooked ...</td>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>4.739414</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0.023433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful production filming technique unassum...</td>\n",
              "      <td>1</td>\n",
              "      <td>162</td>\n",
              "      <td>5.166667</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.109722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful spend hot summer weekend sit...</td>\n",
              "      <td>1</td>\n",
              "      <td>166</td>\n",
              "      <td>4.584337</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.354008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically theres family boy (jake) thinks ther...</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>4.427536</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.057813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter matteis money visually stunning mr matt...</td>\n",
              "      <td>1</td>\n",
              "      <td>230</td>\n",
              "      <td>4.730435</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0.217952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  target  ...  mood  sentiment\n",
              "0  reviewers mentioned 1 oz episode youll hooked ...       1  ...     0   0.023433\n",
              "1  wonderful production filming technique unassum...       1  ...     0   0.109722\n",
              "2  thought wonderful spend hot summer weekend sit...       1  ...     0   0.354008\n",
              "3  basically theres family boy (jake) thinks ther...       0  ...     0  -0.057813\n",
              "4  petter matteis money visually stunning mr matt...       1  ...     0   0.217952\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8H1EEsOGgH7m",
        "colab": {}
      },
      "source": [
        "target = data['target']\n",
        "data.drop(['target'], inplace=True, axis=1)\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, \n",
        "                                                                    target, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=target, \n",
        "                                                                    shuffle=True,\n",
        "                                                                    random_state=42)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sgj01YJMgH7j"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzHwfYBbsgbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text, stem_not_lem=True):\n",
        "    min_length = 3\n",
        "   \n",
        "    tokenized_words = word_tokenize(text)\n",
        "\n",
        "    if stem_not_lem:\n",
        "        tokens = list(map(lambda token: PorterStemmer().stem(token), tokenized_words))\n",
        "    else:\n",
        "        tokens = list(map(lambda token: WordNetLemmatizer().lemmatize(token), tokenized_words))\n",
        "    \n",
        "    p = re.compile('[a-zA-Z]+');\n",
        "    filtered_tokens = list(filter(lambda token:\n",
        "                  p.match(token) and len(token)>=min_length,\n",
        "         tokens)); # check if numbers are needed\n",
        "\n",
        "    return filtered_tokens\n",
        "\n",
        "    \n",
        "def vectorize_with_tf_idf(train_data, tokenizer, test_data=None, max_feats=50000):\n",
        "    tfidf = TfidfVectorizer(tokenizer=tokenizer, \n",
        "                            #min_df=3,\n",
        "                            #max_df=0.90, \n",
        "                            max_features=max_feats,\n",
        "                            use_idf=True, \n",
        "                            sublinear_tf=True,\n",
        "                            norm='l2',\n",
        "                            ngram_range = (1,3));\n",
        "    \n",
        "    vectorised_train_data = tfidf.fit_transform(train_data)\n",
        "    if test_data is None:\n",
        "        return vectorised_train_data, tfidf\n",
        "    else:\n",
        "        vectorised_test_data = tfidf.transform(test_data)\n",
        "        return vectorised_train_data, vectorised_test_data, tfidf"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tkvAl_bdgH7u"
      },
      "source": [
        "## Vectorizing\n",
        "\n",
        "Let's start from 3000 features in tf-idf. Later we will check other values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_z66AclSgH7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9be1ff30-1d7f-4c90-88f8-b19c4e4a534d"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Learn and transform train documents\n",
        "vectorised_train_data, tfidf = vectorize_with_tf_idf(train_data=train_data['review'], \n",
        "                                                                           tokenizer=tokenize,\n",
        "                                                                           max_feats=3000)\n",
        "\n",
        "print('there are ', vectorised_train_data.shape[0], ' samples in the train')\n",
        "num_feats = vectorised_train_data.shape[1]\n",
        "print('there are ', num_feats, ' features in the dataset')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are  35000  samples in the train\n",
            "there are  3000  features in the dataset\n",
            "CPU times: user 3min 25s, sys: 1.29 s, total: 3min 26s\n",
            "Wall time: 3min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFDI6mJMELwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d14c6639-c9ac-4010-e55b-6f68fdfdc30a"
      },
      "source": [
        "train_features = sparse.hstack((vectorised_train_data, train_data.drop(['review'], axis=1).to_numpy()))\n",
        "train_features.shape"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 3009), (15000, 3009))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R3WdGOLbgH7r"
      },
      "source": [
        "# Modeling and scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BAKiX-EhgH7r"
      },
      "source": [
        "Function that will fit our model and show auc roc score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7QCCWG65gH7s",
        "colab": {}
      },
      "source": [
        "# def clf_fit_show_metric(clf, X_train, y_train, X_test, y_test):\n",
        "#     #classifier = OneVsRestClassifier(clf)\n",
        "#     clf.fit(X_train, y_train)\n",
        "\n",
        "#     prob_pred = clf.predict_proba(X_test)[:,1]\n",
        "#     print('auc roc score : ', roc_auc_score(y_test, prob_pred))"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Axv8YbigH70"
      },
      "source": [
        "## SGD classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3vLACdsPgH70"
      },
      "source": [
        "Now we are finding best parameters for SGD classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHEwO6esFevD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6da28a68-d69d-4ec7-8e31-0d5ff9afd2bd"
      },
      "source": [
        "parameters = {'loss': ['log', 'modified_huber'], \n",
        "              'alpha': [1e-5, 1e-4, 5e-4, 1e-3, 1e-2]}\n",
        "grid_clf = GridSearchCV(SGDClassifier(), parameters, scoring='roc_auc', n_jobs=-1,\n",
        "                   cv=5, verbose=1)\n",
        "\n",
        "grid_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5,\n",
              "                                     random_state=None, shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'alpha': [1e-05, 0.0001, 0.0005, 0.001, 0.01],\n",
              "                         'loss': ['log', 'modified_huber']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnQmf8o_GmOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "801fac78-2271-4c49-bf72-2cee3adfba60"
      },
      "source": [
        "pd.DataFrame(grid_clf.cv_results_).sort_values('rank_test_score')[['params', 'mean_test_score', 'mean_fit_time']]"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>mean_fit_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'alpha': 0.0001, 'loss': 'log'}</td>\n",
              "      <td>0.819995</td>\n",
              "      <td>3.563150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'alpha': 0.0005, 'loss': 'modified_huber'}</td>\n",
              "      <td>0.795860</td>\n",
              "      <td>2.957689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'alpha': 0.001, 'loss': 'log'}</td>\n",
              "      <td>0.786721</td>\n",
              "      <td>4.623880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'alpha': 0.001, 'loss': 'modified_huber'}</td>\n",
              "      <td>0.773994</td>\n",
              "      <td>3.169701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'alpha': 0.01, 'loss': 'modified_huber'}</td>\n",
              "      <td>0.773727</td>\n",
              "      <td>2.907726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'alpha': 0.01, 'loss': 'log'}</td>\n",
              "      <td>0.761135</td>\n",
              "      <td>3.866019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'alpha': 1e-05, 'loss': 'log'}</td>\n",
              "      <td>0.754164</td>\n",
              "      <td>3.843386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'alpha': 1e-05, 'loss': 'modified_huber'}</td>\n",
              "      <td>0.739384</td>\n",
              "      <td>2.605306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'alpha': 0.0005, 'loss': 'log'}</td>\n",
              "      <td>0.731478</td>\n",
              "      <td>3.274979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'alpha': 0.0001, 'loss': 'modified_huber'}</td>\n",
              "      <td>0.713987</td>\n",
              "      <td>2.544674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        params  mean_test_score  mean_fit_time\n",
              "2             {'alpha': 0.0001, 'loss': 'log'}         0.819995       3.563150\n",
              "5  {'alpha': 0.0005, 'loss': 'modified_huber'}         0.795860       2.957689\n",
              "6              {'alpha': 0.001, 'loss': 'log'}         0.786721       4.623880\n",
              "7   {'alpha': 0.001, 'loss': 'modified_huber'}         0.773994       3.169701\n",
              "9    {'alpha': 0.01, 'loss': 'modified_huber'}         0.773727       2.907726\n",
              "8               {'alpha': 0.01, 'loss': 'log'}         0.761135       3.866019\n",
              "0              {'alpha': 1e-05, 'loss': 'log'}         0.754164       3.843386\n",
              "1   {'alpha': 1e-05, 'loss': 'modified_huber'}         0.739384       2.605306\n",
              "4             {'alpha': 0.0005, 'loss': 'log'}         0.731478       3.274979\n",
              "3  {'alpha': 0.0001, 'loss': 'modified_huber'}         0.713987       2.544674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2XjobZiagH73"
      },
      "source": [
        "The best model have auc roc score near 0,82"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g_nLN8vVgH73"
      },
      "source": [
        "### Finding best shape of tf-idf matrix\n",
        "\n",
        "Let's make an experiment in which we will find the best shape of tf-idf matrix on the example of the best SGD classifier. The experiment can't guarantee that all the other models will show the same distribution over the considered parameter values but checking all possible feature numbers for all models is very time-consuming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoaL_f6JI6KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3HinbZZZgH74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a7e6804-3aa7-4b49-b14e-da41b5776231"
      },
      "source": [
        "%%time\n",
        "\n",
        "num_features = [1000, 2000, 3000, 5000, 7000, 10000, 15000, 20000]\n",
        "\n",
        "for feats in num_features:\n",
        "    print('Num feats:', feats)\n",
        "    # Learn and transform train documents\n",
        "    vectorised_train_data, tfidf = vectorize_with_tf_idf(train_data=train_data['review'], \n",
        "                                                        tokenizer=tokenize,\n",
        "                                                        max_feats=3000)\n",
        "\n",
        "    train_features = sparse.hstack((vectorised_train_data, train_data.drop(['review'], axis=1).to_numpy()))\n",
        "\n",
        "    clf = SGDClassifier(loss='log', alpha=0.0001)\n",
        "    score = cross_val_score(estimator=clf, X=train_features, y=train_labels, \n",
        "                            scoring='roc_auc', cv=5, n_jobs=-1, verbose=10)\n",
        "    print('score:', score, 'mean:', score.mean(), '\\n')"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num feats: 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   10.2s remaining:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.83168229 0.7590698  0.76264163 0.74945543 0.80676212] mean: 0.7819222530612245 \n",
            "\n",
            "Num feats: 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.8s remaining:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.74099037 0.82909151 0.69466931 0.78513216 0.83379453] mean: 0.7767355755102041 \n",
            "\n",
            "Num feats: 3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.4s remaining:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.83289208 0.73151478 0.66328367 0.79500049 0.63923469] mean: 0.7323851428571428 \n",
            "\n",
            "Num feats: 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.2s remaining:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.66791935 0.62824261 0.84889527 0.63117608 0.76834351] mean: 0.7089153632653062 \n",
            "\n",
            "Num feats: 7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    7.3s remaining:    4.9s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.70397494 0.78175273 0.71943771 0.77683224 0.85722531] mean: 0.767844587755102 \n",
            "\n",
            "Num feats: 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    5.4s remaining:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.84700612 0.85344155 0.85600392 0.61560465 0.69673396] mean: 0.7737580408163265 \n",
            "\n",
            "Num feats: 15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.3s remaining:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.8647418  0.76899649 0.85778359 0.83966653 0.86082384] mean: 0.8384024489795918 \n",
            "\n",
            "Num feats: 20000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.5s remaining:    4.3s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: [0.67410661 0.80934008 0.54406376 0.86169943 0.85703682] mean: 0.7492493387755103 \n",
            "\n",
            "CPU times: user 20min 12s, sys: 5.16 s, total: 20min 18s\n",
            "Wall time: 21min 47s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.4s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uGQziO59gH77"
      },
      "source": [
        "With an increase of number of features model becomes better, but after 15000 features profit is very small. So let's deal with 15000 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ziXRsCAmgH78",
        "colab": {}
      },
      "source": [
        "# Learn and transform train documents\n",
        "vectorised_train_data, vectorised_test_data, tfidf = vectorize_with_tf_idf(train_data=train_data['review'], \n",
        "                                                                           tokenizer=tokenize, \n",
        "                                                                           test_data=test_data['review'],\n",
        "                                                                           max_feats=15000)\n",
        "\n",
        "train_features = sparse.hstack((vectorised_train_data, train_data.drop(['review'], axis=1).to_numpy()))\n",
        "test_features = sparse.hstack((vectorised_test_data, test_data.drop(['review'], axis=1).to_numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g1bvx3eHgH7-"
      },
      "source": [
        "# Support Vector Classification (SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1pvkocexgH7-",
        "colab": {},
        "outputId": "38660f6c-8089-463b-fae7-eecd7897db75"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf_fit_show_metric( SVC(probability=True), \n",
        "                        vectorised_train_data, train_labels, \n",
        "                        vectorised_test_data, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc roc score :  0.825239733071\n",
            "Wall time: 58min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ycjd08rdgH8B"
      },
      "source": [
        "Computing of this methon is very long and result are pretty the same as SGD model gave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xe1ga7pzgH8C"
      },
      "source": [
        "# Naive Bayes classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ig8qiC5PgH8C",
        "colab": {},
        "outputId": "1b962cf8-9f0e-4f9d-9560-641857da2853"
      },
      "source": [
        "NB_functions = [BernoulliNB, MultinomialNB]\n",
        "for NB_func in NB_functions:\n",
        "    print('NB function : ', NB_func)\n",
        "    clf_fit_show_metric(NB_func(), \n",
        "                        vectorised_train_data, train_labels, \n",
        "                        vectorised_test_data, test_labels)\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB function :  <class 'sklearn.naive_bayes.BernoulliNB'>\n",
            "auc roc score :  0.775429017718\n",
            "\n",
            "\n",
            "NB function :  <class 'sklearn.naive_bayes.MultinomialNB'>\n",
            "auc roc score :  0.808277821996\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "81Z7uGLWgH8E"
      },
      "source": [
        "Multinomial Naive Bayes have auc roc score about 0.81, that is a little worse than metric of the SGD model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ7sOdo6MDml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "\n",
        "# classifier = CalibratedClassifierCV(BernoulliNB(), cv=7, method='isotonic')\n",
        "# classifier.fit(train, y_train)\n",
        "\n",
        "# predictions = classifier.predict(test)\n",
        "\n",
        "# print(roc_auc_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DsEZcgYdgH8E"
      },
      "source": [
        "# TruncatedSVD\n",
        "\n",
        "Now let's try to reduce dimension of tf-idf sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I37yiD4PgH8F",
        "colab": {}
      },
      "source": [
        "tsvd = TruncatedSVD(n_components = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgP0cTqjgH8G"
      },
      "source": [
        "Let's make a pipeline to make data preprocessing easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YopvFBXxgH8G",
        "colab": {}
      },
      "source": [
        "preprocessing = Pipeline(steps = [('tfidf', tfidf), ('tsvd',tsvd)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QZ79I1bngH8J"
      },
      "source": [
        "We will estimate efficiency of the decomposition on the example of SGD classifier with the best parameters we found above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-DmiilwkgH8K",
        "colab": {},
        "outputId": "28872446-1c9d-4f0d-bc69-ce0bf3c1cb1f"
      },
      "source": [
        "%%time\n",
        "\n",
        "sgd = SGDClassifier(loss='modified_huber', alpha=0.001)\n",
        "bst_clf_pipe = Pipeline(steps=[('preprocessing', preprocessing),\n",
        "                           ('sgd', sgd)\n",
        "                    ])\n",
        "\n",
        "clf_fit_show_metric(bst_clf_pipe, \n",
        "                               train_data, train_labels, \n",
        "                               test_data, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc roc score :  0.821033932538\n",
            "Wall time: 3min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M934rTUcgH8N"
      },
      "source": [
        "Reducing the dimension of the matrix didn't make a profit but take more time than fitting without SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q5njR6jNgH8O"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fUkc3UfzgH8O",
        "colab": {}
      },
      "source": [
        "TextExpl = TextExplainer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ph2CjEDgH8P"
      },
      "source": [
        "#### Let's find some presentative positive text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWsYdlSNgH8P",
        "colab": {},
        "outputId": "cdea9b5b-cb76-4185-9811-65730ef9239f"
      },
      "source": [
        "for i in range(0,15000):\n",
        "    pos_text = test_data[i]\n",
        "    if(bst_clf_pipe.predict_proba([pos_text])[:,1]>0.97):\n",
        "        positive_index = i\n",
        "        break\n",
        "\n",
        "pos_text = test_data[positive_index]\n",
        "\n",
        "print('Real class : ' , test_labels[positive_index])\n",
        "print('Predicted class : ', bst_clf_pipe.predict([pos_text]))\n",
        "print('Probabilities : ', bst_clf_pipe.predict_proba([pos_text]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real class :  0\n",
            "Predicted class :  [1]\n",
            "Probabilities :  [[0.01444528 0.98555472]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ic7dAnqWgH8T",
        "colab": {}
      },
      "source": [
        "feature_names_tfidf = bst_clf_pipe.named_steps['preprocessing'].named_steps['tfidf']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s0FtePdugH8X",
        "colab": {},
        "outputId": "16faccc3-c45d-4142-f58a-312231ef9aec"
      },
      "source": [
        "%%time\n",
        "\n",
        "TextExpl.fit(pos_text, bst_clf_pipe.predict_proba)\n",
        "display(TextExpl.show_prediction(target_names=feature_names_tfidf.get_feature_names()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=aaron\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.971</b>, score <b>3.496</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.649\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 97.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.153\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"opacity: 0.80\">checked impulse browsing </span><span style=\"background-color: hsl(0, 100.00%, 92.82%); opacity: 0.82\" title=\"-0.082\">store</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.05%); opacity: 0.82\" title=\"-0.095\">couldnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.53%); opacity: 0.92\" title=\"0.589\">pleasantly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.24%); opacity: 0.96\" title=\"0.784\">surprised</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.41%); opacity: 0.82\" title=\"-0.089\">mom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.32%); opacity: 0.83\" title=\"-0.145\">watched</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.78%); opacity: 0.81\" title=\"0.039\">together</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.092\">thoroughly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.79%); opacity: 0.92\" title=\"0.553\">enjoyed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.75%); opacity: 0.81\" title=\"-0.027\">isnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.61%); opacity: 0.83\" title=\"0.121\">typical</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.042\">chickflick</span><span style=\"opacity: 0.80\"> sappy </span><span style=\"background-color: hsl(0, 100.00%, 83.23%); opacity: 0.86\" title=\"-0.277\">tears</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.16%); opacity: 0.84\" title=\"0.210\">definitely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.98%); opacity: 0.83\" title=\"0.133\">touches</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.51%); opacity: 0.84\" title=\"-0.203\">nerve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.75%); opacity: 0.85\" title=\"0.219\">twist</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.31%); opacity: 0.82\" title=\"0.108\">ending</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.33%); opacity: 0.85\" title=\"0.229\">although</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.22%); opacity: 0.83\" title=\"0.147\">unexpected</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.62%); opacity: 0.85\" title=\"0.245\">tragic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.32%); opacity: 0.88\" title=\"0.373\">overall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.12%); opacity: 0.82\" title=\"0.112\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.81%); opacity: 0.82\" title=\"-0.099\">harmed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.21%); opacity: 0.86\" title=\"-0.277\">reese</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.72%); opacity: 0.84\" title=\"-0.177\">witherspoon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.83%); opacity: 0.83\" title=\"-0.155\">actress</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.81%); opacity: 0.83\" title=\"0.155\">debut</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.73%); opacity: 0.97\" title=\"0.833\">definitely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.958\">worth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.78%); opacity: 0.82\" title=\"-0.100\">recognize</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.62%); opacity: 0.81\" title=\"0.041\">supporting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.52%); opacity: 0.82\" title=\"0.105\">play</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.84%); opacity: 0.83\" title=\"-0.155\">important</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.64%); opacity: 0.81\" title=\"-0.054\">supporting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.28%); opacity: 0.82\" title=\"0.091\">roles</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.037\">moon</span><span style=\"opacity: 0.80\"> believable </span><span style=\"background-color: hsl(120, 100.00%, 99.33%); opacity: 0.80\" title=\"0.003\">teenager</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.83%); opacity: 0.81\" title=\"-0.038\">falling</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.91%); opacity: 0.83\" title=\"-0.134\">women</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.52%); opacity: 0.85\" title=\"0.224\">definitely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.57%); opacity: 0.85\" title=\"0.223\">relate</span><span style=\"opacity: 0.80\"> everythingfrom </span><span style=\"background-color: hsl(0, 100.00%, 95.90%); opacity: 0.81\" title=\"-0.037\">witherspoons</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.73%); opacity: 0.83\" title=\"-0.157\">words</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.82%); opacity: 0.86\" title=\"0.311\">subtle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.14%); opacity: 0.81\" title=\"-0.034\">glances</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.84%); opacity: 0.85\" title=\"0.240\">subtle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.51%); opacity: 0.83\" title=\"-0.142\">emotions</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(0, 100.00%, 95.04%); opacity: 0.81\" title=\"-0.049\">raging</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.23%); opacity: 0.82\" title=\"0.076\">typical</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.028\">teenage</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.74%); opacity: 0.81\" title=\"-0.068\">girl</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 86.77%); opacity: 0.84\" title=\"0.197\">shes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.66%); opacity: 0.84\" title=\"0.178\">playing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.22%); opacity: 0.83\" title=\"-0.128\">confused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.37%); opacity: 0.81\" title=\"-0.058\">come</span><span style=\"opacity: 0.80\"> across </span><span style=\"background-color: hsl(0, 100.00%, 88.88%); opacity: 0.83\" title=\"-0.154\">silly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.55%); opacity: 0.83\" title=\"-0.141\">immature</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.54%); opacity: 0.87\" title=\"0.317\">appreciated</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.06%); opacity: 0.82\" title=\"0.078\">considering</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.76%); opacity: 0.87\" title=\"0.312\">today</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 11.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MMsJfOLvgH8Z"
      },
      "source": [
        "Here we can see such words as pleasantly, surprised (and they both together because we 2-grams), enjoyed, worth (with definitely). These words are charachterize this review as positive with probability of 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5jfOs7DkgH8a"
      },
      "source": [
        "#### Let's find some negative text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uRBaEhL8gH8a",
        "colab": {},
        "outputId": "f688e1a7-3f57-4945-ceae-e514a338b3f3"
      },
      "source": [
        "for i in range(0,15000):\n",
        "    neg_text = test_data[i]\n",
        "    if(bst_clf_pipe.predict_proba([neg_text])[:,0]>0.97):\n",
        "        negative_index = i\n",
        "        break\n",
        "\n",
        "neg_text = test_data[negative_index]\n",
        "\n",
        "print('Real class : ' , test_labels[negative_index])\n",
        "print('Predicted class : ', bst_clf_pipe.predict([neg_text]))\n",
        "print('Probabilities : ', bst_clf_pipe.predict_proba([neg_text]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real class :  0\n",
            "Predicted class :  [0]\n",
            "Probabilities :  [[1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REzRBZc6gH8c",
        "colab": {},
        "outputId": "1072ef8f-cf2b-4d0d-8870-533588a924d1"
      },
      "source": [
        "%%time\n",
        "\n",
        "TextExpl.fit(neg_text, bst_clf_pipe.predict_proba)\n",
        "display(TextExpl.show_prediction(target_names=feature_names_tfidf.get_feature_names()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=aamir\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.996</b>, score <b>-5.599</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.258\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 97.05%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.342\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 85.63%); opacity: 0.85\" title=\"0.207\">saw</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.53%); opacity: 0.88\" title=\"0.343\">disaster</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.00%); opacity: 0.89\" title=\"0.380\">talking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.22%); opacity: 0.82\" title=\"-0.102\">volcano</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.18%); opacity: 0.93\" title=\"-0.587\">lot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.20%); opacity: 0.88\" title=\"-0.376\">certainly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.48%); opacity: 0.88\" title=\"0.369\">care</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.34%); opacity: 0.83\" title=\"-0.117\">fact</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.73%); opacity: 0.83\" title=\"-0.146\">volcano</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.14%); opacity: 0.81\" title=\"-0.044\">erupting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.63%); opacity: 0.88\" title=\"-0.365\">underneath</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.18%); opacity: 0.86\" title=\"-0.281\">downtown</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.55%); opacity: 0.82\" title=\"0.081\">la</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.77%); opacity: 0.87\" title=\"0.291\">possible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.29%); opacity: 0.83\" title=\"0.155\">perhaps</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.10%); opacity: 0.81\" title=\"0.044\">isnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.64%); opacity: 0.82\" title=\"-0.095\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.49%); opacity: 0.81\" title=\"-0.039\">isnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.59%); opacity: 0.81\" title=\"0.038\">ill</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.66%); opacity: 0.85\" title=\"0.227\">explain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.49%); opacity: 0.83\" title=\"0.115\">whybr</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.035\">lava</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.96%); opacity: 0.87\" title=\"-0.309\">flows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.48%); opacity: 0.85\" title=\"-0.210\">average</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.50%); opacity: 0.83\" title=\"-0.151\">volcano</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.95%); opacity: 0.82\" title=\"-0.107\">volcano</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.87%); opacity: 0.83\" title=\"-0.126\">vesuvius</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.77%); opacity: 0.82\" title=\"-0.093\">etna</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.066\">mount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.32%); opacity: 0.84\" title=\"-0.193\">pinatubo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.56%); opacity: 0.82\" title=\"-0.081\">together</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.45%); opacity: 0.87\" title=\"0.298\">look</span><span style=\"opacity: 0.80\"> barbecue </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.063\">lava</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.79%); opacity: 0.84\" title=\"-0.184\">flowing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.59%); opacity: 0.82\" title=\"-0.096\">volcano</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.52%); opacity: 0.83\" title=\"-0.150\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.57%); opacity: 0.84\" title=\"0.168\">director</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.28%); opacity: 0.92\" title=\"-0.557\">lot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.82%); opacity: 0.84\" title=\"0.183\">money</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.89%); opacity: 0.84\" title=\"0.162\">spend</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.85%); opacity: 0.81\" title=\"0.024\">wonder</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.12%); opacity: 0.81\" title=\"-0.032\">spent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.90%); opacity: 0.86\" title=\"0.288\">special</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.11%); opacity: 0.84\" title=\"-0.158\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.10%); opacity: 0.85\" title=\"0.239\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.27%); opacity: 0.82\" title=\"0.070\">saying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.09%); opacity: 0.81\" title=\"0.032\">hired</span><span style=\"opacity: 0.80\"> top </span><span style=\"background-color: hsl(0, 100.00%, 99.63%); opacity: 0.80\" title=\"-0.001\">cast</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.22%); opacity: 0.84\" title=\"-0.175\">opposite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.05%); opacity: 0.83\" title=\"0.140\">call</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.18%); opacity: 0.89\" title=\"-0.401\">performances</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.91%); opacity: 0.90\" title=\"0.459\">unbelievably</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.894\">poor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.92%); opacity: 0.89\" title=\"0.407\">entire</span><span style=\"opacity: 0.80\"> worsebr </span><span style=\"background-color: hsl(120, 100.00%, 79.56%); opacity: 0.88\" title=\"0.342\">whats</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.55%); opacity: 0.85\" title=\"0.230\">wrong</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.10%); opacity: 0.85\" title=\"0.239\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.19%); opacity: 0.83\" title=\"0.120\">probably</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.22%); opacity: 0.83\" title=\"0.156\">ask</span><span style=\"opacity: 0.80\"> tell </span><span style=\"background-color: hsl(120, 100.00%, 93.58%); opacity: 0.81\" title=\"0.066\">comes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.37%); opacity: 0.87\" title=\"0.300\">idea</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.19%); opacity: 0.81\" title=\"-0.057\">standing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.97%); opacity: 0.81\" title=\"-0.060\">yards</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.54%); opacity: 0.84\" title=\"0.169\">feet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.063\">lava</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.19%); opacity: 0.83\" title=\"-0.138\">without</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.42%); opacity: 0.85\" title=\"-0.232\">getting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.12%); opacity: 0.82\" title=\"0.088\">burned</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.69%); opacity: 0.83\" title=\"-0.147\">hide</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.99%); opacity: 0.86\" title=\"-0.263\">heath</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.64%); opacity: 0.80\" title=\"0.007\">sinking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.59%); opacity: 0.83\" title=\"0.149\">earth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.85%); opacity: 0.84\" title=\"-0.163\">flow</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.063\">lava</span><span style=\"opacity: 0.80\"> isnt </span><span style=\"background-color: hsl(120, 100.00%, 86.63%); opacity: 0.84\" title=\"0.187\">foot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.72%); opacity: 0.82\" title=\"-0.111\">high</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.43%); opacity: 0.85\" title=\"-0.211\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.08%); opacity: 0.81\" title=\"0.058\">wouldnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.41%); opacity: 0.83\" title=\"-0.116\">proud</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.32%); opacity: 0.94\" title=\"0.612\">wrote</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.28%); opacity: 0.92\" title=\"0.557\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.54%); opacity: 0.89\" title=\"0.417\">apparently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.17%); opacity: 0.84\" title=\"0.196\">script</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.45%); opacity: 0.81\" title=\"0.053\">writers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.129\">hollywood</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.24%); opacity: 0.82\" title=\"-0.086\">mind</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.96%); opacity: 0.81\" title=\"-0.060\">believability</span><span style=\"opacity: 0.80\"> long </span><span style=\"background-color: hsl(120, 100.00%, 87.73%); opacity: 0.84\" title=\"0.165\">pays</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.88%); opacity: 0.92\" title=\"0.540\">money</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.40%); opacity: 0.82\" title=\"-0.068\">moneybr</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.00%); opacity: 0.85\" title=\"-0.220\">youll</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.26%); opacity: 0.83\" title=\"0.119\">probably</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.63%); opacity: 0.81\" title=\"-0.065\">agree</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.63%); opacity: 0.81\" title=\"-0.065\">hollywoods</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.06%); opacity: 0.84\" title=\"0.198\">disaster</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.98%); opacity: 0.93\" title=\"-0.565\">worth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.47%); opacity: 0.82\" title=\"-0.098\">310</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 14.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o2UwUSDQgH8e"
      },
      "source": [
        "And here we see words disaster, poor, unbelievably. Interesting that there is a lot of speculation about the script of the movie. So this review is negative with great chance"
      ]
    }
  ]
}