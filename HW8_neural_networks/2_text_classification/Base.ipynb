{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCgeqDWhEhrL"
   },
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9IsPcWDEhrO",
    "outputId": "fe4246c0-0612-42ed-8b32-71446e5f11cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Embedding, Bidirectional, LSTM, GlobalAveragePooling1D, Conv1D, Dropout\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras\n",
    "import gensim\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db-KhHCOEhrX"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvRWciyWEhrY",
    "outputId": "ca9a03d8-28b8-448b-bf2f-4ec5c93bb29d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (18341, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oleg\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8342</td>\n",
       "      <td>Александр</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>6 входов, предохранитель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8342</td>\n",
       "      <td>Елена</td>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>Я являюсь пользователем Пилотов уже больше 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>Леонид</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>хорошо мелет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>Сергей</td>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>Компактная</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>Ольга</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>Цена и качество</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  product_id       name        date  \\\n",
       "0     1.0        8342  Александр  2017-04-12   \n",
       "1     5.0        8342      Елена  2015-08-04   \n",
       "2     5.0        5311     Леонид  2017-07-16   \n",
       "3     4.0        5311     Сергей  2017-06-28   \n",
       "4     5.0        5311      Ольга  2017-01-21   \n",
       "\n",
       "                                            feedback  \n",
       "0                           6 входов, предохранитель  \n",
       "1  Я являюсь пользователем Пилотов уже больше 10 ...  \n",
       "2                                       хорошо мелет  \n",
       "3                                         Компактная  \n",
       "4                                    Цена и качество  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('feedback.csv')\n",
    "columns = data.columns[:5]\n",
    "data = data[columns]\n",
    "print('data shape:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSrsILtTEhrc",
    "outputId": "fc3a5dfa-d537-4be0-e34a-90eed486b33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target size: 18341\n",
      "\n",
      "number of target labels: 5\n"
     ]
    }
   ],
   "source": [
    "# target extracting\n",
    "y = data.pop('rating')\n",
    "print(\"target size:\", y.shape[0])\n",
    "\n",
    "# reducing the number of labels to 5 by rounding fractional values\n",
    "y_round = round(y)\n",
    "num_labels = len(set(y_round))\n",
    "print(\"\\nnumber of target labels:\", num_labels)\n",
    "\n",
    "# providing target into one-hot form\n",
    "y_arr = ((np.arange(num_labels) + 1) == np.array(y_round)[:, None]).astype(\n",
    "    np.int8)\n",
    "\n",
    "# deleting non informative columns\n",
    "data.drop(['product_id', 'name', 'date'], 1, inplace=True)\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 100\n",
    "\n",
    "encoded_data = [\n",
    "    one_hot(feedback, max_features) for feedback in list(data['feedback'].str.lower())\n",
    "]\n",
    "padded_data = pad_sequences(encoded_data, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the data because we are not going to capture any time-related dependencies. But, of course, it would be better to sort the data and split it without shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSrsILtTEhrc",
    "outputId": "fc3a5dfa-d537-4be0-e34a-90eed486b33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train: (12379, 100)  y_train: (12379, 5) \n",
      "X_dev: (4127, 100)  y_dev: (4127, 5)\n",
      "X_test: (1835, 100)  ny_test: (1835, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(padded_data,\n",
    "                                                            y_arr,\n",
    "                                                            stratify=y_arr,\n",
    "                                                            test_size=0.1,\n",
    "                                                            random_state=0)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev,\n",
    "                                                  y_train_dev,\n",
    "                                                  stratify=y_train_dev,\n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=0)\n",
    "print('\\nX_train:', X_train.shape, ' y_train:', y_train.shape,\n",
    "      '\\nX_dev:', X_dev.shape, ' y_dev:', y_dev.shape)\n",
    "print('X_test:', X_test.shape, ' ny_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1caLMOYgEhrg"
   },
   "outputs": [],
   "source": [
    "def metrics_evaluate(X_test, y_test, model):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    # the weirdest way of calculating accuracy\n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if (np.argmax(y_pred[i]) == np.argmax(y_test[i])):\n",
    "            correct += 1\n",
    "    accuracy = correct / len(y_test)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    df = pd.DataFrame([[accuracy, roc_auc]],\n",
    "                      columns=['accuracy', 'roc_auc'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pumZbqYmEhri"
   },
   "source": [
    "## Recurrent neural network for sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epFb7LmREhrj",
    "outputId": "8b4800e4-bc25-4021-8baf-9ba8707037a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 100, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,379,461\n",
      "Trainable params: 1,379,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "\n",
    "#initializing random initializer\n",
    "random_initializer = keras.initializers.RandomUniform(minval=-0.5,\n",
    "                                                      maxval=0.5,\n",
    "                                                      seed=42)\n",
    "\n",
    "# Initialising the NN\n",
    "model = Sequential()\n",
    "\n",
    "# layers\n",
    "model.add(Embedding(input_dim=max_features, \n",
    "                    output_dim=128, \n",
    "                    input_length=maxlen, \n",
    "                    name='embedding_layer'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(\n",
    "    Dense(num_labels,\n",
    "          kernel_initializer=random_initializer,\n",
    "          activation='softmax'))\n",
    "\n",
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ9CSVZFEhrp",
    "outputId": "628c1f9d-dffa-45e9-c247-dfd1031a30e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "387/387 [==============================] - 28s 66ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 3.0212 - val_accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "387/387 [==============================] - 26s 66ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 3.0017 - val_accuracy: 0.5769\n",
      "Epoch 3/10\n",
      "387/387 [==============================] - 23s 59ms/step - loss: 0.0281 - accuracy: 0.9890 - val_loss: 3.3189 - val_accuracy: 0.5457\n",
      "Epoch 4/10\n",
      "387/387 [==============================] - 23s 59ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 3.0720 - val_accuracy: 0.5740\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "#initializing optimizer\n",
    "adam_opt = Adam(lr=LEARNING_RATE,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=None,\n",
    "                decay=0.0,\n",
    "                amsgrad=False)\n",
    "\n",
    "# Compiling the NN\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Defining early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_accuracy',\n",
    "                          min_delta=0.01,\n",
    "                          patience=2,\n",
    "                          restore_best_weights=True,\n",
    "                          verbose=1,\n",
    "                          mode='max')\n",
    "\n",
    "# Defining checkpoint callback\n",
    "filepath = './RNN.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "# Train the NN\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_dev, y_dev),\n",
    "                    batch_size=32,\n",
    "                    epochs=N_EPOCHS,\n",
    "                    callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCTZwXgtEhrt",
    "outputId": "0bd5aeda-3b2e-4958-8013-81e4a8ef135e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.585286</td>\n",
       "      <td>0.823126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy   roc_auc\n",
       "RNN  0.585286  0.823126"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_result = metrics_evaluate(X_test, y_test, model)\n",
    "RNN_result.rename({0: \"RNN\"}, axis='index', inplace=True)\n",
    "RNN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.50192672e-05, 6.42105646e-04, 1.08773194e-04, 1.80777541e-04,\n",
       "        9.99013305e-01],\n",
       "       [2.45709361e-06, 9.81260906e-04, 7.48079270e-04, 2.39994060e-05,\n",
       "        9.98244166e-01],\n",
       "       [3.93233222e-07, 2.99892463e-07, 2.06866980e-06, 9.99993563e-01,\n",
       "        3.64092693e-06],\n",
       "       ...,\n",
       "       [6.04394241e-04, 4.47876460e-04, 8.25484216e-01, 4.17288952e-02,\n",
       "        1.31734625e-01],\n",
       "       [2.20873975e-03, 2.29806552e-04, 9.12868069e-04, 4.87306342e-03,\n",
       "        9.91775513e-01],\n",
       "       [5.40591171e-03, 8.06183994e-01, 1.47168770e-01, 5.43230213e-03,\n",
       "        3.58090885e-02]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just for check that we may reload the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdnVpHCfEhrx",
    "outputId": "51b4c892-7b5e-43d2-ead1-da2acc3f06bf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.585286</td>\n",
       "      <td>0.823126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy   roc_auc\n",
       "RNN  0.585286  0.823126"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model('./RNN.hdf5')\n",
    "\n",
    "RNN_result = metrics_evaluate(X_test, y_test, loaded_model)\n",
    "RNN_result.rename({0: \"RNN\"}, axis='index', inplace=True)\n",
    "RNN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.50192672e-05, 6.42105646e-04, 1.08773194e-04, 1.80777541e-04,\n",
       "        9.99013305e-01],\n",
       "       [2.45709361e-06, 9.81260906e-04, 7.48079270e-04, 2.39994060e-05,\n",
       "        9.98244166e-01],\n",
       "       [3.93233222e-07, 2.99892463e-07, 2.06866980e-06, 9.99993563e-01,\n",
       "        3.64092693e-06],\n",
       "       ...,\n",
       "       [6.04394241e-04, 4.47876460e-04, 8.25484216e-01, 4.17288952e-02,\n",
       "        1.31734625e-01],\n",
       "       [2.20873975e-03, 2.29806552e-04, 9.12868069e-04, 4.87306342e-03,\n",
       "        9.91775513e-01],\n",
       "       [5.40591171e-03, 8.06183994e-01, 1.47168770e-01, 5.43230213e-03,\n",
       "        3.58090885e-02]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-ywcTZdEhr1"
   },
   "source": [
    "## Fasttext with n-grams for text classification\n",
    "\n",
    "https://github.com/ShreyaKhare/imdb_fasttext/blob/master/imdb_fasttext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uQB-DFoEhr2"
   },
   "outputs": [],
   "source": [
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "#                     new_list.append(token_indice[ngram])\n",
    "                    new_list = np.append(new_list, (token_indice[ngram]))\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences\n",
    "\n",
    "\n",
    "def build_model(maxlen, max_features, embedding=None):\n",
    "    model = Sequential()\n",
    "\n",
    "    #initializing random initializer\n",
    "    random_initializer = keras.initializers.RandomUniform(minval=-0.5,\n",
    "                                                          maxval=0.5,\n",
    "                                                          seed=42)\n",
    "\n",
    "    if (embedding == None):\n",
    "        # we start off with an efficient embedding layer which maps\n",
    "        # our vocab indices into embedding_dims dimensions\n",
    "        model.add(\n",
    "            Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=maxlen,\n",
    "                      embeddings_initializer=random_initializer))\n",
    "    else:\n",
    "        model.add(embedding)\n",
    "\n",
    "    # we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "    # of all words in the document\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(\n",
    "        Dense(num_labels,\n",
    "              kernel_initializer=random_initializer,\n",
    "              activation='softmax'))\n",
    "\n",
    "    #initializing optimizer\n",
    "    adam_opt = Adam(lr=LEARNING_RATE,\n",
    "                    beta_1=0.9,\n",
    "                    beta_2=0.999,\n",
    "                    epsilon=None,\n",
    "                    decay=0.0,\n",
    "                    amsgrad=False)\n",
    "\n",
    "    # Compiling the NN\n",
    "    model.compile(optimizer=adam_opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFFmRfEmEhr4"
   },
   "source": [
    "### 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBEe8zZHEhr-"
   },
   "outputs": [],
   "source": [
    "ngram_range = 1\n",
    "\n",
    "# Defining early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_accuracy',\n",
    "                          min_delta=0.001,\n",
    "                          patience=4,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='max')\n",
    "\n",
    "# Defining checkpoint callback\n",
    "filepath = './fasttext_1_gram.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cfCF3OHCEhsB",
    "outputId": "89122d9f-dbed-42da-cf3f-dc32a8db8fc6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 50)           500000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 500,255\n",
      "Trainable params: 500,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = build_model(maxlen, max_features)\n",
    "\n",
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBeEWGIYEhsD",
    "outputId": "4f5f9e60-280d-4f66-ea08-946fdede4c8b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.3618 - accuracy: 0.4953 - val_loss: 1.1751 - val_accuracy: 0.5973\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 1.1477 - accuracy: 0.6029 - val_loss: 1.1393 - val_accuracy: 0.5973\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 1.1079 - accuracy: 0.5983 - val_loss: 1.0993 - val_accuracy: 0.5980\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 1.0609 - accuracy: 0.5967 - val_loss: 1.0537 - val_accuracy: 0.6012\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.9976 - accuracy: 0.6076 - val_loss: 1.0109 - val_accuracy: 0.6084\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 3s 6ms/step - loss: 0.9273 - accuracy: 0.6364 - val_loss: 0.9785 - val_accuracy: 0.6208\n",
      "Epoch 7/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.8748 - accuracy: 0.6594 - val_loss: 0.9532 - val_accuracy: 0.6317\n",
      "Epoch 8/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.8308 - accuracy: 0.6832 - val_loss: 0.9389 - val_accuracy: 0.6368\n",
      "Epoch 9/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.7859 - accuracy: 0.6994 - val_loss: 0.9233 - val_accuracy: 0.6506\n",
      "Epoch 10/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.7404 - accuracy: 0.7221 - val_loss: 0.9167 - val_accuracy: 0.6470\n",
      "Epoch 11/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.7142 - accuracy: 0.7396 - val_loss: 0.9111 - val_accuracy: 0.6513\n",
      "Epoch 12/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.6807 - accuracy: 0.7542 - val_loss: 0.9076 - val_accuracy: 0.6520\n",
      "Epoch 13/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.6504 - accuracy: 0.7720 - val_loss: 0.9081 - val_accuracy: 0.6550\n",
      "Epoch 14/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.6155 - accuracy: 0.7885 - val_loss: 0.9129 - val_accuracy: 0.6484\n",
      "Epoch 15/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 0.5870 - accuracy: 0.7992 - val_loss: 0.9177 - val_accuracy: 0.6533\n",
      "Epoch 16/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.5752 - accuracy: 0.8069 - val_loss: 0.9207 - val_accuracy: 0.6499\n",
      "Epoch 17/100\n",
      "387/387 [==============================] - 2s 6ms/step - loss: 0.5345 - accuracy: 0.8217 - val_loss: 0.9281 - val_accuracy: 0.6477\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6eb114cc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjxIvERSEhsG",
    "outputId": "db008d12-6f9f-40dc-fd90-1f114aa656be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 gram</th>\n",
       "      <td>0.640872</td>\n",
       "      <td>0.888153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy   roc_auc\n",
       "1 gram  0.640872  0.888153"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram1_result = metrics_evaluate(X_test, y_test, model)\n",
    "gram1_result.rename({0: \"1 gram\"}, axis='index', inplace=True)\n",
    "gram1_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdAnndiLEhsK",
    "outputId": "1beae6ed-0d32-4b3d-d1a6-ab8f964caa62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 gram</th>\n",
       "      <td>0.640872</td>\n",
       "      <td>0.888153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy   roc_auc\n",
       "1 gram  0.640872  0.888153"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model('./fasttext_1_gram.hdf5')\n",
    "\n",
    "gram1_result = metrics_evaluate(X_test, y_test, loaded_model)\n",
    "gram1_result.rename({0: \"1 gram\"}, axis='index', inplace=True)\n",
    "gram1_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_tvapaMvEhsO"
   },
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6hAsny8EhsP",
    "outputId": "f1705471-b41b-49e6-a5ec-e99570b26578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2-gram features\n",
      "\n",
      "Average train sequence length: 199\n",
      "Average dev sequence length: 181\n",
      "Average test sequence length: 180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_range = 2\n",
    "\n",
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features\\n'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in X_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features_2_gram = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    X_train_2_gram = add_ngram(X_train, token_indice, ngram_range)\n",
    "    X_dev_2_gram = add_ngram(X_dev, token_indice, ngram_range)\n",
    "    X_test_2_gram = add_ngram(X_test, token_indice, ngram_range)\n",
    "    \n",
    "    train_avg_len = np.mean(list(map(len, X_train_2_gram)), dtype=int)\n",
    "    print('Average train sequence length: {}'.format(train_avg_len))\n",
    "    dev_avg_len = np.mean(list(map(len, X_dev_2_gram)), dtype=int)\n",
    "    print('Average dev sequence length: {}'.format(dev_avg_len))\n",
    "    test_avg_len = np.mean(list(map(len, X_test_2_gram)), dtype=int)\n",
    "    print('Average test sequence length: {}\\n'.format(test_avg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiiQL0E4EhsS",
    "outputId": "3af8fb4e-cda1-427f-9158-338e711f9552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12379, 199)\n",
      "X_dev shape: (4127, 199)\n",
      "X_test shape: (1835, 199) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making sequences the same length\n",
    "\n",
    "maxlen_2gram = max(train_avg_len, dev_avg_len, test_avg_len)\n",
    "X_train_2_gram = pad_sequences(X_train_2_gram, maxlen=maxlen_2gram)\n",
    "X_dev_2_gram = pad_sequences(X_dev_2_gram, maxlen=maxlen_2gram)\n",
    "X_test_2_gram = pad_sequences(X_test_2_gram, maxlen=maxlen_2gram)\n",
    "print('X_train shape:', X_train_2_gram.shape)\n",
    "print('X_dev shape:', X_dev_2_gram.shape)\n",
    "print('X_test shape:', X_test_2_gram.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBg1eJB1EhsV",
    "outputId": "630cde97-06db-4b64-accb-be9338dbf6c8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 199, 50)           14389200  \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 14,389,455\n",
      "Trainable params: 14,389,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(maxlen=maxlen_2gram, \n",
    "                    max_features=max_features_2_gram)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fIDnMfGEhsW",
    "outputId": "4ec67c3f-25f7-4f04-a692-b36578fc7a1b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "387/387 [==============================] - 57s 145ms/step - loss: 1.3640 - accuracy: 0.4849 - val_loss: 1.1806 - val_accuracy: 0.5973\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 55s 143ms/step - loss: 1.1450 - accuracy: 0.5992 - val_loss: 1.1433 - val_accuracy: 0.5973\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 55s 143ms/step - loss: 1.0674 - accuracy: 0.5988 - val_loss: 1.0955 - val_accuracy: 0.5978\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 56s 145ms/step - loss: 0.9619 - accuracy: 0.6092 - val_loss: 1.0334 - val_accuracy: 0.6067\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 58s 150ms/step - loss: 0.8221 - accuracy: 0.6764 - val_loss: 0.9869 - val_accuracy: 0.6172\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 58s 150ms/step - loss: 0.7012 - accuracy: 0.7492 - val_loss: 0.9492 - val_accuracy: 0.6271\n",
      "Epoch 7/100\n",
      "387/387 [==============================] - 58s 151ms/step - loss: 0.5936 - accuracy: 0.8116 - val_loss: 0.9243 - val_accuracy: 0.6331\n",
      "Epoch 8/100\n",
      "387/387 [==============================] - 58s 149ms/step - loss: 0.5046 - accuracy: 0.8572 - val_loss: 0.9110 - val_accuracy: 0.6441\n",
      "Epoch 9/100\n",
      "387/387 [==============================] - 57s 148ms/step - loss: 0.4162 - accuracy: 0.8885 - val_loss: 0.9035 - val_accuracy: 0.6445\n",
      "Epoch 10/100\n",
      "387/387 [==============================] - 57s 147ms/step - loss: 0.3691 - accuracy: 0.9073 - val_loss: 0.8960 - val_accuracy: 0.6450\n",
      "Epoch 11/100\n",
      "387/387 [==============================] - 59s 153ms/step - loss: 0.3109 - accuracy: 0.9298 - val_loss: 0.9143 - val_accuracy: 0.6419\n",
      "Epoch 12/100\n",
      "387/387 [==============================] - 58s 151ms/step - loss: 0.2745 - accuracy: 0.9360 - val_loss: 0.9040 - val_accuracy: 0.6433\n",
      "Epoch 13/100\n",
      "387/387 [==============================] - 56s 145ms/step - loss: 0.2421 - accuracy: 0.9529 - val_loss: 0.8970 - val_accuracy: 0.6504\n",
      "Epoch 14/100\n",
      "387/387 [==============================] - 57s 146ms/step - loss: 0.2055 - accuracy: 0.9592 - val_loss: 0.8966 - val_accuracy: 0.6523\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f68f5e2c88>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0.001,\n",
    "                          patience=4,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='min')\n",
    "\n",
    "# Defining checkpoint callback\n",
    "filepath = './fasttext_2_gram.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "model.fit(X_train_2_gram,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=(X_dev_2_gram, y_dev),\n",
    "          callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2URdhHAzEhsZ",
    "outputId": "6724be8f-b7b2-4a55-ee24-14ff4902ab7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 gram</th>\n",
       "      <td>0.621253</td>\n",
       "      <td>0.888147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy   roc_auc\n",
       "2 gram  0.621253  0.888147"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_result = metrics_evaluate(X_test_2_gram, y_test, model)\n",
    "gram2_result.rename({0: \"2 gram\"}, axis='index', inplace=True)\n",
    "gram2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IS0yASZEhsb",
    "outputId": "b3929ee2-0acf-4238-ba89-fd3f2bafa9a7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 gram</th>\n",
       "      <td>0.621253</td>\n",
       "      <td>0.888147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy   roc_auc\n",
       "2 gram  0.621253  0.888147"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model('./fasttext_2_gram.hdf5')\n",
    "\n",
    "gram2_result = metrics_evaluate(X_test_2_gram, y_test, loaded_model)\n",
    "gram2_result.rename({0: \"2 gram\"}, axis='index', inplace=True)\n",
    "gram2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-gram model gave almost the same results as the 2-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhswUFApEhsf"
   },
   "source": [
    "# Pre-trained word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NeQEmB7sEhsg"
   },
   "source": [
    "Loading word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yloCphqxEhsg",
    "outputId": "e5a57e9a-44ad-4bcc-c03b-80258d0950ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://rusvectores.org/ru/models/\n",
    "model_path = 'ruwikiruscorpora_superbigrams_2_1_2.vec'\n",
    "keyed_vectors = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=False, limit=10000)\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "weights = keyed_vectors.vectors      \n",
    "\n",
    "# set `trainable` as `False` to use the pretrained word embedding\n",
    "# No extra mem usage here as `Embedding` layer doesn't create any new matrix for weights\n",
    "embedding = Embedding(\n",
    "    input_dim=weights.shape[0], output_dim=weights.shape[1],\n",
    "    weights=[weights], trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ov7nH8SEhsi"
   },
   "source": [
    "Adding loaded model as embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONf3YY_KEhsi",
    "outputId": "bd7853f0-5df7-4152-92f4-4eacfc3877fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         115328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,115,973\n",
      "Trainable params: 115,973\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = Sequential()\n",
    "\n",
    "#initializing random initializer\n",
    "random_initializer = keras.initializers.RandomUniform(minval=-0.5,\n",
    "                                                      maxval=0.5,\n",
    "                                                      seed=42)\n",
    "\n",
    "pre_trained_model.add(embedding)\n",
    "\n",
    "pre_trained_model.add(\n",
    "    Conv1D(128, 3, kernel_regularizer=l1_l2(1e-7, 1e-7), padding='same'))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "pre_trained_model.add(GlobalAveragePooling1D())\n",
    "\n",
    "pre_trained_model.add(\n",
    "    Dense(num_labels,\n",
    "          kernel_initializer=random_initializer,\n",
    "          activation='softmax'))\n",
    "\n",
    "#initializing optimizer\n",
    "adam_opt = Adam(lr=LEARNING_RATE,\n",
    "                beta_1=0.9,\n",
    "                beta_2=0.999,\n",
    "                epsilon=None,\n",
    "                decay=0.0,\n",
    "                amsgrad=False)\n",
    "\n",
    "# Compiling the NN\n",
    "pre_trained_model.compile(optimizer=adam_opt,\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es2neWutEhsm"
   },
   "source": [
    "Just for interest let's check pre-trained model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyFZqcGeEhsn",
    "outputId": "cc9204b8-faa7-473b-fb2a-41ea44d2466a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre-trained word2vec</th>\n",
       "      <td>0.59782</td>\n",
       "      <td>0.745075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy   roc_auc\n",
       "pre-trained word2vec   0.59782  0.745075"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trained_result = metrics_evaluate(X_test, y_test, pre_trained_model)\n",
    "pre_trained_result.rename({0: \"pre-trained word2vec\"}, axis='index', inplace=True)\n",
    "pre_trained_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmIvPODvEhsq"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=5, \n",
    "                          verbose=1, mode='max')\n",
    "\n",
    "# Defining checkpoint callback\n",
    "filepath='./pre_trained_w2v.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
    "                             verbose=0, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWbXRtmFEhst",
    "outputId": "1f18a1ce-140a-4c92-8fb2-ef0bf8a81623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "387/387 [==============================] - 8s 22ms/step - loss: 1.1748 - accuracy: 0.5946 - val_loss: 1.1648 - val_accuracy: 0.5975\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 8s 21ms/step - loss: 1.1639 - accuracy: 0.5981 - val_loss: 1.1543 - val_accuracy: 0.5973\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 8s 22ms/step - loss: 1.1580 - accuracy: 0.5979 - val_loss: 1.1658 - val_accuracy: 0.5968\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 8s 21ms/step - loss: 1.1562 - accuracy: 0.5971 - val_loss: 1.1487 - val_accuracy: 0.5958\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 8s 21ms/step - loss: 1.1414 - accuracy: 0.5975 - val_loss: 1.1495 - val_accuracy: 0.5975\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 8s 21ms/step - loss: 1.1440 - accuracy: 0.5992 - val_loss: 1.1549 - val_accuracy: 0.5949\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f68b40d5c0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trained_model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pgp9g16Ehsv",
    "outputId": "660f9034-9ed1-4f24-91ee-21b70bd53cd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre-trained word2vec</th>\n",
       "      <td>0.589101</td>\n",
       "      <td>0.821746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy   roc_auc\n",
       "pre-trained word2vec  0.589101  0.821746"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trained_result = metrics_evaluate(X_test, y_test, pre_trained_model)\n",
    "pre_trained_result.rename({0: \"pre-trained word2vec\"}, axis='index', inplace=True)\n",
    "pre_trained_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9rw9Fs9Ehsx",
    "outputId": "cd1a5dc5-253f-47a8-86da-06329878e4e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre-trained word2vec</th>\n",
       "      <td>0.597275</td>\n",
       "      <td>0.820582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy   roc_auc\n",
       "pre-trained word2vec  0.597275  0.820582"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = load_model('./pre_trained_w2v.hdf5')\n",
    "\n",
    "pre_trained_result = metrics_evaluate(X_test, y_test, loaded_model)\n",
    "pre_trained_result.rename({0: \"pre-trained word2vec\"}, axis='index', inplace=True)\n",
    "pre_trained_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulam4D6xEhs0"
   },
   "source": [
    "# Metrics comparison and conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BosIBA0OEhs1",
    "outputId": "3b0451b9-95d1-45fb-b3ce-10ba528c99d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RNN</th>\n",
       "      <td>0.585286</td>\n",
       "      <td>0.823126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 gram</th>\n",
       "      <td>0.640872</td>\n",
       "      <td>0.888153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 gram</th>\n",
       "      <td>0.621253</td>\n",
       "      <td>0.888147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre-trained word2vec</th>\n",
       "      <td>0.597275</td>\n",
       "      <td>0.820582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy   roc_auc\n",
       "RNN                   0.585286  0.823126\n",
       "1 gram                0.640872  0.888153\n",
       "2 gram                0.621253  0.888147\n",
       "pre-trained word2vec  0.597275  0.820582"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([RNN_result, gram1_result,gram2_result, pre_trained_result])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsaYYCKeEhs3"
   },
   "source": [
    "**Results are more or less similar for all models. Best scores are achieved by n-gram models. 2-gram fasttext model is noticeably slower than others because of the increased vocabulary. Finally, our winner is 1-gram fasttext model trained from scratch** "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Base.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
